resources:
  jobs:
    test_runner_job:
      name: "iris_test_runner_${bundle.target}"
      
      # 🔄 Configuração de execução
      timeout_seconds: 1800  # 30 minutos para testes completos
      max_concurrent_runs: 1
      
      # 📧 Notificações
      email_notifications:
        on_failure:
          - ${var.notification_email}
        on_success:
          - ${var.notification_email}
      
      # 🖥️ Configuração de Cluster (Serverless por padrão)
      job_clusters:
        - job_cluster_key: "test_cluster"
          new_cluster:
            spark_version: "13.3.x-scala2.12"
            node_type_id: "i3.xlarge"
            driver_node_type_id: "i3.xlarge"
            num_workers: 1
            # Para testes, usamos cluster pequeno
            spark_conf:
              "spark.databricks.adaptive.enabled": "true"
              "spark.databricks.adaptive.coalescePartitions.enabled": "true"
            custom_tags:
              Environment: ${bundle.target}
              Project: "iris_pipeline"
              JobType: "testing"
      
      # 📋 Tarefas do job
      tasks:
        - task_key: "run_tests"
          job_cluster_key: "test_cluster"
          
          notebook_task:
            notebook_path: ${workspace.file_path}/notebooks/test_runner
            base_parameters:
              env: ${bundle.target}
              catalog: ${var.catalog_name}
              schema: ${var.schema_name}
          
          # ⏱️ Timeout específico para esta tarefa
          timeout_seconds: 1200  # 20 minutos
          
          # 🔄 Retry em caso de falha
          retry_on_timeout: true
          max_retries: 2
      
      # 🏷️ Tags para organização
      tags:
        environment: ${bundle.target}
        project: "iris_mlops"
        job_type: "testing"
        
      # 🔄 Agendamento (descomentado para ativar)
      # schedule:
      #   quartz_cron_expression: "0 0 6 * * ?"  # Todo dia às 6:00 AM
      #   timezone_id: "America/Sao_Paulo"
      #   pause_status: "UNPAUSED"
