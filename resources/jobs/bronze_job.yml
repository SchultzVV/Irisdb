resources:
  jobs:
    bronze_job:
      name: iris_bronze_ingestion
      # üñ•Ô∏è CONFIGURA√á√ÉO DE CLUSTER (comentado - atualmente usando Serverless)
      # 
      # Op√ß√£o 1: Usar cluster existente por ID
      # existing_cluster_id: ${var.cluster_id}
      #
      # Op√ß√£o 2: Criar cluster job-espec√≠fico com monitoramento
      # new_cluster:
      #   cluster_name: "bronze-job-cluster"
      #   spark_version: "13.3.x-scala2.12"
      #   node_type_id: "i3.xlarge"
      #   driver_node_type_id: "i3.xlarge"
      #   num_workers: 2
      #   autotermination_minutes: 30
      #   spark_conf:
      #     "spark.databricks.adaptive.enabled": "true"
      #     "spark.databricks.adaptive.coalescePartitions.enabled": "true"
      #     # ElasticSearch monitoring configuration
      #     "spark.iris.elasticsearch.host": "${var.elasticsearch_host}"
      #     "spark.iris.elasticsearch.port": "${var.elasticsearch_port}"
      #     "spark.iris.teams.webhook": "${var.teams_webhook}"
      #     "spark.driver.extraJavaOptions": "-Dlog4j.configuration=file:${var.log4j_path}"
      #     "spark.executor.extraJavaOptions": "-Dlog4j.configuration=file:${var.log4j_path}"
      #   custom_tags:
      #     Job: "bronze_ingestion"
      #     Environment: "${bundle.target}"
      #     monitoring: "enabled"
      #
      # Op√ß√£o 3: Usar cluster pool (mais eficiente para m√∫ltiplos jobs)
      # new_cluster:
      #   cluster_name: "bronze-job-from-pool"
      #   instance_pool_id: "pool-id-here"
      #   spark_version: "13.3.x-scala2.12"
      #   num_workers: 2
      #   autotermination_minutes: 30
      
      tasks:
        - task_key: ingest_bronze
          description: "Ingesta os dados brutos no Delta Lake (camada Bronze) usando Unity Catalog"
          notebook_task:
            notebook_path: /Workspace/Users/vitorvazschultz@gmail.com/.bundle/iris_bundle/dev/files/notebooks/01_ingest_bronze
            base_parameters:
              source: ${var.source}
              output_bronze_table: ${var.output_bronze_table}
              catalog_name: ${var.catalog_name}
              schema_name: ${var.schema_name}
          timeout_seconds: 3600
          max_retries: 1
          # üñ•Ô∏è Task-level cluster override (se necess√°rio diferente do job-level)
          # existing_cluster_id: "task-specific-cluster-id"
      
      # üìß Notifica√ß√µes aprimoradas
      email_notifications:
        on_failure:
          - "vitorvazschultz@gmail.com"
      
      # üîî Teams webhooks (comentado at√© configura√ß√£o)
      # webhook_notifications:
      #   on_failure:
      #     - id: "teams_webhook"
      #       url: "${var.teams_webhook}"
      #   on_success:
      #     - id: "teams_success"
      #       url: "${var.teams_webhook}"
      
      tags:
        environment: "${bundle.target}"
        cost_center: "ml_ops"
        monitoring: "enabled"
        pipeline_stage: "bronze"