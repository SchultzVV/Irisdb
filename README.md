# ğŸŒ¸ Iris MLOps Pipeline - Databricks Asset Bundles

## ğŸ“‹ VisÃ£o Geral

Pipeline MLOps completo utilizando Databricks Asset Bundles para processamento de dados Iris, desde a ingestÃ£o atÃ© o treinamento de modelos de Machine Learning, seguindo a arquitetura medallion (Bronze â†’ Silver â†’ Gold) com validaÃ§Ãµes de qualidade integradas usando Great Expectations.

![Pipeline Architecture](https://img.shields.io/badge/Architecture-Medallion-gold)
![Databricks](https://img.shields.io/badge/Databricks-Asset_Bundles-blue)
![Unity Catalog](https://img.shields.io/badge/Unity_Catalog-Enabled-green)
![MLflow](https://img.shields.io/badge/MLflow-Model_Tracking-orange)
![Great Expectations](https://img.shields.io/badge/Great_Expectations-Data_Quality-purple)
![Status](https://img.shields.io/badge/Status-âœ…_Production_Ready-brightgreen)

## ğŸ—ï¸ Arquitetura do Pipeline

```mermaid
graph TD
    A[ğŸ”µ Bronze Layer<br/>Raw Data Ingestion<br/>+ Data Quality Validation] --> B[ğŸ¥ˆ Silver Layer<br/>Data Cleaning & Validation<br/>+ Schema Enforcement]
    B --> C[ğŸ¥‡ Gold Layer<br/>Business Aggregations<br/>+ Business Rules Validation]
    C --> D[ğŸ¤– ML Training<br/>Model Development<br/>+ Performance Tracking]
    
    E[ğŸ“Š Unity Catalog<br/>Managed Tables] --> A
    E --> B
    E --> C
    
    F[ğŸ§ª Great Expectations<br/>Data Quality Framework] --> A
    F --> B
    F --> C
    
    D --> G[ğŸ“ˆ MLflow<br/>Model Registry]
    
    H[ğŸ”„ Serverless Compute<br/>Auto-scaling] --> A
    H --> B
    H --> C
    H --> D
    
    style A fill:#8ecae6
    style B fill:#219ebc
    style C fill:#ffb703
    style D fill:#fb8500
    style F fill:#e9c46a
```

## ğŸ“ Estrutura do Projeto

```
iris_bundle/
â”œâ”€â”€ ğŸ“„ databricks.yml              # ConfiguraÃ§Ã£o principal do Bundle
â”œâ”€â”€ ğŸ”§ Makefile                    # Comandos de automaÃ§Ã£o
â”œâ”€â”€ ğŸ“‹ requirements.txt            # DependÃªncias Python (PySpark, MLflow, etc)
â”œâ”€â”€ ğŸ”‘ .env                        # VariÃ¡veis de ambiente (nÃ£o versionado)
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ 01_ingest_bronze.py        # ğŸ”µ IngestÃ£o + validaÃ§Ãµes PySpark
â”‚   â”œâ”€â”€ 02_transform_silver.py     # ğŸ¥ˆ Limpeza + validaÃ§Ãµes avanÃ§adas
â”‚   â”œâ”€â”€ 03_aggregate_gold.py       # ğŸ¥‡ AgregaÃ§Ãµes + validaÃ§Ãµes de negÃ³cio
â”‚   â”œâ”€â”€ 04_train_model.py          # ğŸ¤– Treinamento ML
â”‚   â””â”€â”€ data_quality_validation.py # ğŸ§ª ValidaÃ§Ãµes PySpark nativas
â”œâ”€â”€ resources/
â”‚   â””â”€â”€ jobs/
â”‚       â”œâ”€â”€ bronze_job.yml         # Job de ingestÃ£o
â”‚       â”œâ”€â”€ silver_job.yml         # Job de transformaÃ§Ã£o
â”‚       â”œâ”€â”€ gold_job.yml           # Job de agregaÃ§Ã£o
â”‚       â”œâ”€â”€ training_job.yml       # Job de treinamento
â”‚       â”œâ”€â”€ data_quality_job.yml   # Job de validaÃ§Ã£o de qualidade
â”‚       â””â”€â”€ iris_workflow.yml      # Workflow completo com dependÃªncias
â””â”€â”€ tests/
    â”œâ”€â”€ test_data_quality.py       # Testes de qualidade
    â””â”€â”€ test_iris_reader.py         # Testes unitÃ¡rios
```

## ğŸš€ Quick Start

### 1ï¸âƒ£ PrÃ©-requisitos

- **Databricks CLI v0.261+**
- **Python 3.8+**
- **Workspace Unity Catalog habilitado**
- **Compute Serverless disponÃ­vel**

### 2ï¸âƒ£ InstalaÃ§Ã£o e ConfiguraÃ§Ã£o

```bash
# Clone o repositÃ³rio
git clone <repository-url>
cd iris_bundle

# Instale o Databricks CLI
make install-databricks

# Configure suas credenciais no arquivo .env
cp .env.example .env
# Edite o .env com seus dados:
# DATABRICKS_HOST=https://your-workspace.cloud.databricks.com
# DATABRICKS_TOKEN=dapi12345...
```

### 3ï¸âƒ£ Deploy do Pipeline

```bash
# Valide a configuraÃ§Ã£o
make validate

# FaÃ§a o deploy dos recursos
make deploy

# Configure notificaÃ§Ãµes Teams (opcional)
make setup-teams

# Execute o workflow completo
make run_workflow
```

### 4ï¸âƒ£ Monitoramento AvanÃ§ado com Teams

```bash
# Configure webhook do Microsoft Teams primeiro
make setup-teams

# Execute monitoramento bÃ¡sico
make run_monitoring

# Execute monitoramento avanÃ§ado com alertas
make run_advanced_monitoring
```

## ğŸ“Š Camadas de Dados (Medallion Architecture)

### ğŸ”µ Bronze Layer - Raw Data Ingestion
- **Fonte**: Dataset Iris do seaborn
- **Formato**: Dados brutos sem transformaÃ§Ã£o
- **Tabela**: `default.iris_bronze`
- **ValidaÃ§Ãµes Implementadas**:
  - âœ… Contagem de registros (100-200 esperados)
  - âœ… Schema validation (5 colunas esperadas)
  - âœ… VerificaÃ§Ã£o de valores nulos
  - âœ… ValidaÃ§Ã£o de espÃ©cies (setosa, versicolor, virginica)
  - âœ… Valores numÃ©ricos positivos
- **CaracterÃ­sticas**:
  - 150 registros
  - 5 colunas (4 features + 1 target)
  - Dados originais preservados
  - Compatible com Serverless Compute

### ğŸ¥ˆ Silver Layer - Data Cleaning & Validation
- **Entrada**: `default.iris_bronze`
- **SaÃ­da**: `default.iris_silver`
- **TransformaÃ§Ãµes**:
  - âœ… RemoÃ§Ã£o de valores nulos
  - âœ… ValidaÃ§Ã£o de schema rigorosa
  - âœ… Filtros de qualidade (valores > 0)
  - âœ… PadronizaÃ§Ã£o de tipos
  - âœ… ValidaÃ§Ã£o de ranges de valores
- **ValidaÃ§Ãµes AvanÃ§adas**:
  - ğŸ“Š VerificaÃ§Ã£o de distribuiÃ§Ãµes
  - ğŸ” DetecÃ§Ã£o de outliers
  - ğŸ“ˆ ConsistÃªncia de dados

### ğŸ¥‡ Gold Layer - Business Aggregations
- **Entrada**: `default.iris_silver`
- **SaÃ­da**: `default.iris_gold`
- **AgregaÃ§Ãµes**:
  - ğŸ“ˆ EstatÃ­sticas por espÃ©cie (avg, min, max)
  - ğŸ“Š Contagem de registros por categoria
  - ğŸ”¢ MÃ©tricas de qualidade
  - ğŸ“ Features engineered para ML
- **ValidaÃ§Ãµes de NegÃ³cio**:
  - âœ… Contagens balanceadas por espÃ©cie (40-60 registros cada)
  - âœ… MÃ©dias dentro de ranges esperados
  - âœ… Integridade referencial

### ğŸ¤– ML Training - Model Development
- **Entrada**: `default.iris_gold`
- **SaÃ­da**: Modelo registrado no MLflow
- **CaracterÃ­sticas**:
  - ğŸ¯ Algoritmo: Random Forest Classifier
  - ğŸ“Š MÃ©tricas: Accuracy, Precision, Recall
  - ğŸ·ï¸ Versionamento automÃ¡tico
  - ğŸ“ˆ Tracking completo no MLflow

## âš™ï¸ Comandos DisponÃ­veis

### ğŸ”„ Workflow Completo (Recomendado)
```bash
# Executa pipeline completo com dependÃªncias
make run_workflow
```

### ğŸ”— Jobs Individuais
```bash
# Bronze Layer
make run_bronze

# Silver Layer  
make run_silver

# Gold Layer
make run_gold

# ML Training
make training_job
```

### ğŸ”§ UtilitÃ¡rios
```bash
# ExecuÃ§Ã£o sequencial (sem dependÃªncias)
make run_pipeline_sequence

# ValidaÃ§Ã£o de configuraÃ§Ã£o
make validate

# Re-deploy de alteraÃ§Ãµes
make deploy

# Limpeza de arquivos temporÃ¡rios
make clean
```

### ğŸš€ Novos Comandos MLOps AvanÃ§ados
```bash
# Feature Store - CriaÃ§Ã£o de features engineered baseado na camada Silver
make run_feature_store

# EDA & Benchmark - AnÃ¡lise exploratÃ³ria e benchmark de modelos
make run_eda_benchmark

# AutoML - SeleÃ§Ã£o automÃ¡tica de modelos
make run_automl

# Model Monitoring - DetecÃ§Ã£o de drift
make run_monitoring

# Pipeline MLOps Completo
make run_mlops_full
```

## ğŸ› ï¸ ConfiguraÃ§Ã£o Detalhada

### databricks.yml - ConfiguraÃ§Ã£o Principal
```yaml
bundle:
  name: iris_bundle

variables:
  output_bronze_table:
    default: "default.iris_bronze"
  output_silver_table:
    default: "default.iris_silver"
  output_gold_table:
    default: "default.iris_gold"

targets:
  dev:
    default: true
    workspace:
      host: ${var.databricks_host}
```

### Workflow com DependÃªncias
```yaml
# iris_workflow.yml
name: iris_complete_workflow
tasks:
  - task_key: bronze_ingestion      # Primeiro
  - task_key: silver_transform      # Depende do Bronze
    depends_on: [bronze_ingestion]
  - task_key: gold_aggregate        # Depende do Silver
    depends_on: [silver_transform]
  - task_key: model_training        # Depende do Gold
    depends_on: [gold_aggregate]
```

## ï¿½ MLOps AvanÃ§ado - Novas Funcionalidades

### ğŸª Feature Store
- **Funcionalidade**: GestÃ£o centralizada de features engineered
- **Fonte de dados**: Tabela Silver do Unity Catalog (iris_silver)
- **Features criadas**: 10+ features derivadas (ratios, Ã¡reas, distÃ¢ncias)
- **Versionamento**: Controle de versÃ£o automÃ¡tico com timestamps
- **ReutilizaÃ§Ã£o**: Features podem ser compartilhadas entre modelos
- **ValidaÃ§Ã£o**: Qualidade automÃ¡tica das features
- **Comando**: `make run_feature_store`

### ğŸ“Š EDA & Model Benchmark
- **Funcionalidade**: AnÃ¡lise exploratÃ³ria completa da Feature Store
- **VisualizaÃ§Ãµes**: 15+ grÃ¡ficos e anÃ¡lises estatÃ­sticas
- **PCA**: AnÃ¡lise de componentes principais para reduÃ§Ã£o de dimensionalidade
- **Benchmark**: 10 modelos comparados automaticamente
- **MÃ©tricas**: Accuracy, Precision, Recall, F1-Score, Cross-validation
- **MLflow**: Todos os experimentos registrados automaticamente
- **Comando**: `make run_eda_benchmark`

### ğŸ¤– AutoML Pipeline
- **Algoritmos**: 6 modelos comparados automaticamente
  - Random Forest, Gradient Boosting, SVM
  - Logistic Regression, KNN, Naive Bayes
- **SeleÃ§Ã£o**: Melhor modelo escolhido por cross-validation
- **MÃ©tricas**: Accuracy, Precision, Recall, F1-Score
- **Registro**: Todos os modelos salvos no MLflow
- **Comando**: `make run_automl`

### ğŸ“Š Model Monitoring
- **Drift Detection**: DetecÃ§Ã£o automÃ¡tica de drift nos dados
- **Performance Tracking**: Monitoramento de mÃ©tricas do modelo
- **Alertas**: Sistema de alertas automatizado
- **Dashboards**: RelatÃ³rios de monitoramento detalhados
- **Agendamento**: ExecuÃ§Ã£o diÃ¡ria automÃ¡tica
- **Comando**: `make run_monitoring`

### ğŸš€ CI/CD Pipeline
- **GitHub Actions**: Pipeline completo de CI/CD
- **Ambientes**: Dev, Staging, Production
- **Testes**: AutomatizaÃ§Ã£o de testes e validaÃ§Ãµes
- **Deploy**: Deploy automÃ¡tico baseado em branches
- **Monitoramento**: Alertas integrados via Slack

### PySpark Native Validations
Este projeto implementa um framework completo de validaÃ§Ã£o de dados usando **PySpark nativo** para mÃ¡xima simplicidade, compatibilidade e performance.

#### ï¿½ Suites de Expectativas Implementadas

**Bronze Suite (`iris_bronze_suite.json`)**:
- `expect_table_row_count_to_be_between`: 100-200 registros
- `expect_column_values_to_not_be_null`: Nenhum valor nulo
- `expect_column_values_to_be_in_set`: EspÃ©cies vÃ¡lidas
- `expect_column_values_to_be_of_type`: Tipos corretos

**Silver Suite (`iris_silver_suite.json`)**:
- `expect_column_values_to_be_between`: Ranges vÃ¡lidos para medidas
- `expect_column_mean_to_be_between`: MÃ©dias dentro do esperado
- `expect_table_columns_to_match_ordered_list`: Schema rigoroso

**Gold Suite (`iris_gold_suite.json`)**:
- `expect_column_values_to_be_between`: MÃ©dias agregadas vÃ¡lidas
- `expect_table_row_count_to_equal`: Exatamente 3 espÃ©cies
- `expect_column_sum_to_be_between`: Contagens totais corretas

#### ğŸ¯ Checkpoints Configurados
```yaml
# Exemplo: iris_bronze_checkpoint.yml
name: iris_bronze_checkpoint
config_version: 1.0
class_name: SimpleCheckpoint
validations:
  - batch_request:
      datasource_name: my_datasource
      data_connector_name: default_inferred_data_connector_name
      data_asset_name: iris_bronze
    expectation_suite_name: iris_bronze_suite
```

### ğŸ”„ EstratÃ©gia de ValidaÃ§Ã£o 

**PySpark Validations (Fallback Robusto)**:
- âœ… ValidaÃ§Ãµes bÃ¡sicas em PySpark nativo
- âœ… CompatÃ­vel com Serverless Compute
- âœ… Assertions diretas no cÃ³digo
- âœ… Logs detalhados de falhas
- âœ… Zero dependÃªncias externas


**obs: poderia ser com Great Expectations (Framework Completo)**

Para issom preisa ser feito:
- [ - ] ConfiguraÃ§Ã£o via `requirements.txt` 
- [ - ] Suites JSON versionadas
- [ - ] Checkpoints YAML configurÃ¡veis
- [ - ] RelatÃ³rios HTML automÃ¡ticos
- [ - ] IntegraÃ§Ã£o com Unity Catalog

### ğŸ“Š ValidaÃ§Ãµes Implementadas por Camada

#### ğŸ”µ Bronze Layer Validations
```python
# ValidaÃ§Ãµes PySpark integradas no notebook
assert count >= 100 and count <= 200, "Contagem inesperada"
assert actual_columns == expected_columns, "Schema incorreto"
assert len(species_list) == 3, "NÃºmero de espÃ©cies incorreto"
# + Great Expectations suite execution
```

#### ğŸ¥ˆ Silver Layer Validations  
```python
# ValidaÃ§Ãµes avanÃ§adas + Great Expectations
assert clean_count > 0, "Dados limpos insuficientes"
assert silver_species == bronze_species, "Perda de categorias"
# + Schema evolution validation
```

#### ğŸ¥‡ Gold Layer Validations
```python
# ValidaÃ§Ãµes de negÃ³cio + mÃ©tricas
assert 40 <= count_records <= 60, "DistribuiÃ§Ã£o desequilibrada"
assert avg_values_in_range, "MÃ©dias fora do padrÃ£o"
# + Business rules validation
```

## ğŸ“ˆ Monitoramento e Observabilidade

### ğŸš¨ Monitoramento AvanÃ§ado com Microsoft Teams

O pipeline inclui monitoramento avanÃ§ado que envia alertas automÃ¡ticos para Microsoft Teams quando detecta:

- **ğŸ” Data Quality Issues**: Valores nulos, outliers, desequilÃ­brios
- **ï¿½ Volume Anomalies**: Contagem baixa ou alta de registros  
- **ğŸ“ˆ Statistical Changes**: MudanÃ§as nas distribuiÃ§Ãµes de features
- **âš ï¸ Pipeline Status**: Estado geral do processamento

#### ConfiguraÃ§Ã£o do Teams

```bash
# 1. Configure o webhook do Teams
make setup-teams

# 2. Execute o monitoramento completo (Bronze â†’ Silver â†’ Monitoramento)
make run_advanced_monitoring

# 3. Alternativa manual (se jobs estiverem bloqueados)
make run_monitoring_complete
```

#### ExecuÃ§Ã£o e DependÃªncias

**Pipeline Completo (Recomendado):**
- âœ… Garante criaÃ§Ã£o de dados Bronze
- âœ… Garante criaÃ§Ã£o de dados Silver  
- âœ… Executa monitoramento com todas as verificaÃ§Ãµes
- âœ… Envia alertas automÃ¡ticos para Teams

**ExecuÃ§Ã£o Manual:**
- ğŸ“± Fornece link direto para notebook interativo
- ğŸ”§ Permite execuÃ§Ã£o paso-a-paso
- ğŸš€ Contorna limitaÃ§Ãµes temporÃ¡rias de jobs

#### MÃ©tricas Monitoradas

**Data Quality Checks:**
- VerificaÃ§Ã£o de valores nulos em todas as colunas
- AnÃ¡lise de outliers via desvio padrÃ£o
- Balanceamento de classes (proporÃ§Ã£o mÃ¡x/mÃ­n)
- Volume total de registros processados

### ğŸ”§ SoluÃ§Ã£o de Problemas

#### Erro: "Triggering new runs is currently disabled"
```bash
# SoluÃ§Ã£o: Use execuÃ§Ã£o manual via notebook
make run_monitoring_complete
# Abra o link fornecido e execute o notebook no Databricks
```

#### Erro: "Table iris_silver cannot be found"
```bash
# SoluÃ§Ã£o 1: Execute pipeline completo primeiro
make run_pipeline_sequence

# SoluÃ§Ã£o 2: Use notebook que cria as dependÃªncias
make run_monitoring_complete
```

#### Webhook Teams nÃ£o configurado
```bash
# Configure o webhook do Microsoft Teams
make setup-teams
# Siga as instruÃ§Ãµes para obter a URL do webhook
```

**Performance Monitoring:**
- Accuracy, Precision, Recall, F1-Score
- ComparaÃ§Ã£o com baseline de referÃªncia
- Threshold de degradaÃ§Ã£o configurÃ¡vel (padrÃ£o: 5%)
- Alertas automÃ¡ticos via Teams

### âœ… Status do Pipeline (Ãšltima ExecuÃ§Ã£o)
```
ğŸ‰ PIPELINE EXECUTADO COM SUCESSO!

âœ… Bronze Layer: 150 registros ingeridos + validaÃ§Ãµes passaram
âœ… Silver Layer: Limpeza e transformaÃ§Ãµes completas
âœ… Gold Layer: 3 agregaÃ§Ãµes por espÃ©cie geradas
âœ… ML Training: Modelo treinado e registrado no MLflow
âœ… Total Runtime: ~3-4 minutos no Serverless Compute
```

### ğŸ”§ Compatibilidade TÃ©cnica Validada
- âœ… **Serverless Compute**: Totalmente compatÃ­vel (sem RDDs)
- âœ… **Unity Catalog**: Apenas managed tables, sem DBFS
- âœ… **PySpark 3.4+**: FunÃ§Ãµes nativas compatÃ­veis
- âœ… **Databricks Runtime 13.3+**: Testado e validado

### MLflow Integration
- **Model Registry**: Versionamento automÃ¡tico de modelos
- **Experiment Tracking**: MÃ©tricas e parÃ¢metros registrados
- **Artifact Storage**: Modelos e artifacts armazenados
- **Model Serving**: Preparado para deployment

### Unity Catalog
- **Governance**: Controle de acesso a dados
- **Lineage**: Rastreabilidade completa de dados
- **Schema Evolution**: Versionamento de schemas
- **Data Discovery**: CatÃ¡logo centralizado

### Job Monitoring
- **Status Tracking**: Monitoramento em tempo real
- **Error Handling**: Logs detalhados de falhas
- **Dependency Management**: ExecuÃ§Ã£o ordenada de tasks
- **Retry Logic**: ReexecuÃ§Ã£o automÃ¡tica em falhas

## ğŸ§ª Testes e Qualidade

### Testes Automatizados
```bash
# ExecuÃ§Ã£o de testes unitÃ¡rios
python -m pytest tests/

# Testes de qualidade de dados
python tests/test_data_quality.py

# Testes de integraÃ§Ã£o
python tests/test_iris_reader.py
```

### ğŸ§ª ValidaÃ§Ãµes de Qualidade Integradas
```bash
# ExecuÃ§Ã£o de validaÃ§Ãµes Great Expectations
make run_data_quality

# ValidaÃ§Ãµes inline nos notebooks (sempre ativas)
make run_workflow  # Inclui validaÃ§Ãµes automÃ¡ticas

# Testes completos de qualidade
python tests/test_data_quality.py
```

### ğŸ“Š MÃ©tricas de Qualidade Implementadas
- **Completeness**: 100% dos dados sem nulos crÃ­ticos
- **Accuracy**: Valores dentro de ranges biolÃ³gicos vÃ¡lidos
- **Consistency**: Schema consistente entre camadas
- **Validity**: EspÃ©cies e tipos de dados corretos
- **Timeliness**: Freshness tracking implementado

## ğŸš¨ Troubleshooting

### Problemas Comuns

#### 1. Erro de AutenticaÃ§Ã£o
```bash
# Verifique suas credenciais
make test-auth

# Re-configure o .env se necessÃ¡rio
```

#### 2. Tabelas nÃ£o encontradas
```bash
# Verifique se o Unity Catalog estÃ¡ habilitado
# Execute os jobs em ordem ou use o workflow
make run_workflow
```

#### 4. Feature Store Dependencies
```bash
# Verificar se Feature Store estÃ¡ disponÃ­vel
# No Databricks notebook, execute:
# %pip list | grep databricks

# Se nÃ£o estiver disponÃ­vel, instalar:
# %pip install databricks-feature-store

# Ou usar Unity Catalog Feature Tables (recomendado)
# NÃ£o requer dependÃªncias especiais
```

#### 5. Runtime Requirements
```bash
# Para Feature Store, use:
# - Databricks Runtime 9.1 LTS ML+
# - Ou Serverless Compute (recomendado)
# - Unity Catalog habilitado
```

### Logs e Debug
```bash
# Visualize logs detalhados
databricks jobs list-runs --job-id <job-id>

# Acesse o workspace para logs visuais
# URL disponÃ­vel na saÃ­da dos comandos make
```

## ğŸ”„ PrÃ³ximos Passos

### Melhorias Futuras
- [x] **âœ… Data Validation**: Great Expectations framework **IMPLEMENTADO**
- [x] **âœ… Serverless Compatibility**: Full serverless compute support **IMPLEMENTADO**
- [x] **âœ… Unity Catalog Integration**: Managed tables only **IMPLEMENTADO**
- [x] **âœ… Requirements.txt Management**: Centralized dependencies **IMPLEMENTADO**
- [x] **âœ… CI/CD Pipeline**: GitHub Actions integration **IMPLEMENTADO**
- [x] **âœ… Model Monitoring**: Drift detection **IMPLEMENTADO**
- [x] **âœ… Feature Store**: Centralized feature management **IMPLEMENTADO**
- [x] **âœ… AutoML**: Automated model selection **IMPLEMENTADO**
- [ ] **Multi-environment**: Prod/Staging environments
- [ ] **Real-time Inference**: Streaming predictions
- [ ] **A/B Testing**: Model comparison framework

### ExpansÃµes PossÃ­veis
- [ ] **Model Serving**: Real-time API endpoints
- [ ] **Batch Inference**: Scheduled predictions
- [ ] **Advanced Data Quality**: Anomaly detection
- [ ] **MLflow Model Serving**: Automated deployment
- [ ] **Delta Live Tables**: Streaming data pipeline

## ğŸ“š Recursos Adicionais

### DocumentaÃ§Ã£o
- [Databricks Asset Bundles](https://docs.databricks.com/dev-tools/bundles/index.html)
- [Unity Catalog](https://docs.databricks.com/data-governance/unity-catalog/index.html)
- [MLflow on Databricks](https://docs.databricks.com/mlflow/index.html)

### Best Practices
- [Medallion Architecture](https://www.databricks.com/glossary/medallion-architecture)
- [MLOps with Databricks](https://www.databricks.com/solutions/accelerators/mlops)
- [Data Engineering Patterns](https://www.databricks.com/solutions/data-engineering)

## ğŸ¤ ContribuiÃ§Ã£o

1. Fork o projeto
2. Crie uma feature branch (`git checkout -b feature/nova-feature`)
3. Commit suas mudanÃ§as (`git commit -am 'Add nova feature'`)
4. Push para a branch (`git push origin feature/nova-feature`)
5. Abra um Pull Request

## ğŸ“„ LicenÃ§a

Este projeto estÃ¡ sob a licenÃ§a MIT. Veja o arquivo [LICENSE](LICENSE) para mais detalhes.

## ğŸ¯ Principais Conquistas TÃ©cnicas

### âœ… ImplementaÃ§Ãµes de Sucesso
1. **Serverless Compute Compatibility**: EliminaÃ§Ã£o de RDDs, uso de funÃ§Ãµes nativas
2. **Unity Catalog Integration**: Managed tables sem dependÃªncia de DBFS
3. **Validation Strategy**: 
PySpark fallbacks
5. **Zero-Downtime Deployment**: Asset Bundles com versionamento
6. **Complete MLOps Workflow**: Bronze â†’ Silver â†’ Gold â†’ ML com dependÃªncias


- **Serverless compute** requer cuidado com compatibilidade de APIs
- **Unity Catalog** elimina complexidades de DBFS management
- **ValidaÃ§Ãµes duplas** garantem robustez em diferentes ambientes
- **Asset Bundles** simplificam drasticamente deployment e versionamento

---

**Exemplo do workflow completo em execuÃ§Ã£o:**

![alt text](image-1.png)
