# ğŸŒ¸ Iris MLOps Pipeline - Unity Catalog

## ğŸ“‹ VisÃ£o Geral

Pipeline de Machine Learning para classificaÃ§Ã£o do dataset Iris usando **Unity Catalog** como camada de governanÃ§a de dados e **MLflow** para gerenciamento de modelos. Sistema simplificado e pronto para produÃ§Ã£o com **Serverless Computing** e **monitoramento ElasticSearch integrado**.

## â­ **IMPORTANTE: ConfiguraÃ§Ã£o de Clusters**

ğŸ“– **Consulte o arquivo [`CLUSTER_CONFIG_GUIDE.md`](CLUSTER_CONFIG_GUIDE.md)** para informaÃ§Ãµes detalhadas sobre:
- Como configurar clusters especÃ­ficos vs Serverless
- OtimizaÃ§Ãµes de performance e custos  
- ConfiguraÃ§Ãµes para desenvolvimento vs produÃ§Ã£o
- **Este Ã© o ponto mais importante para customizaÃ§Ã£o do projeto!**

## ğŸ—ï¸ Arquitetura Unity Catalog

```
ğŸ“Š Dataset Iris (UCI/sklearn)
       â†“
ğŸ¥‰ workspace.default.iris_bronze (Raw data)
       â†“
ğŸ¥ˆ workspace.default.iris_silver (Cleaned data)
       â†“     â†“
ğŸ¥‡ iris_gold â† ğŸ¤– MLflow Model Registry
       â†“           â†“
ğŸ“‹ Analytics â† ğŸ“Š Model Inference â†’ ğŸ”” Alerts
```

## ğŸ”„ Pipeline Simplificado

### Jobs Essenciais (5 notebooks)

| Ordem | Job | DescriÃ§Ã£o | Unity Catalog Table | Compute |
|-------|-----|-----------|-------------------|---------|
| 1ï¸âƒ£ | **Bronze** | IngestÃ£o dataset Iris | `workspace.default.iris_bronze` | Serverless |
| 2ï¸âƒ£ | **Silver** | Limpeza e transformaÃ§Ã£o | `workspace.default.iris_silver` | Serverless |
| 3ï¸âƒ£ | **Gold** | AgregaÃ§Ãµes para analytics | `workspace.default.iris_gold` | Serverless |
| 4ï¸âƒ£ | **Training** | ML model + MLflow registry | MLflow Model | Serverless |
| 5ï¸âƒ£ | **Inference** | Model predictions + visualizations | `workspace.default.iris_inference_*` | Serverless |

### Fluxo Sequencial
```
ğŸ¥‰ Bronze â†’ ğŸ¥ˆ Silver â†’ ğŸ¥‡ Gold â†’ ğŸ¤– Training â†’ ï¿½ Inference
```

## ğŸš€ Comandos Principais

### Pipeline Completa
```bash
# Executa toda a pipeline sequencialmente
make run_pipeline
```

### Jobs Individuais
```bash
make run_bronze     # IngestÃ£o
make run_silver     # TransformaÃ§Ã£o
make run_gold       # AgregaÃ§Ã£o  
make run_training   # ML Training
make run_inference  # Model Inference + Visualizations
```

### Deploy e ValidaÃ§Ã£o
```bash
make validate       # Validar configuraÃ§Ã£o
make deploy         # Deploy para Databricks
make status         # Status do projeto
make help           # Ver todos os comandos
```

## ğŸ“Š Monitoramento e Observabilidade

### ElasticSearch + Kibana Dashboard
- **Logs centralizados**: Todos os pipelines enviam logs para ElasticSearch
- **Dashboard Kibana**: VisualizaÃ§Ãµes em tempo real de execuÃ§Ãµes, erros e mÃ©tricas
- **Alertas Teams**: NotificaÃ§Ãµes automÃ¡ticas para falhas e sucessos
- **MÃ©tricas ML**: Tracking de performance dos modelos

### ConfiguraÃ§Ã£o do Monitoramento
```bash
# 1. Configure as variÃ¡veis de ambiente
export ELASTICSEARCH_HOST="your-elasticsearch-host"
export ELASTICSEARCH_PORT="9200"
export TEAMS_WEBHOOK_URL="your-teams-webhook-url"

# 2. Deploy da infraestrutura de monitoramento
./scripts/deploy_monitoring.sh

# 3. Atualize o bundle com configuraÃ§Ãµes de monitoramento
databricks bundle deploy --target dev
```

### Dashboard Kibana
- **URL**: `http://your-kibana-host:5601/app/dashboards#/view/iris-pipeline-overview`
- **Ãndice**: `iris-pipeline-logs`
- **VisualizaÃ§Ãµes**:
  - Status dos pipelines em tempo real
  - Timeline de execuÃ§Ãµes
  - Checks de qualidade de dados
  - MÃ©tricas de performance dos modelos
  - Logs de erro e alertas

### Teams Notifications
- **InÃ­cio de pipeline**: NotificaÃ§Ã£o azul com parÃ¢metros
- **Sucesso**: NotificaÃ§Ã£o verde com mÃ©tricas
- **Falha**: NotificaÃ§Ã£o vermelha com detalhes do erro
- **Data Quality**: Alertas quando validaÃ§Ãµes falham

## ğŸ“Š Unity Catalog - GovernanÃ§a de Dados

### CatÃ¡logo e Schema
- **Catalog**: `workspace`
- **Schema**: `default`
- **Managed Tables**: Todas as tabelas sÃ£o gerenciadas pelo Unity Catalog
- **Compute**: Serverless (configuraÃ§Ã£o de cluster disponÃ­vel no [`CLUSTER_CONFIG_GUIDE.md`](CLUSTER_CONFIG_GUIDE.md))

### Tabelas Criadas
```sql
-- Bronze Layer (Raw data)
workspace.default.iris_bronze
  â”œâ”€â”€ sepal_length: double
  â”œâ”€â”€ sepal_width: double  
  â”œâ”€â”€ petal_length: double
  â”œâ”€â”€ petal_width: double
  â”œâ”€â”€ species: string
  â”œâ”€â”€ ingestion_timestamp: timestamp
  â”œâ”€â”€ source: string
  â””â”€â”€ batch_id: string

-- Silver Layer (Cleaned data)  
workspace.default.iris_silver
  â”œâ”€â”€ sepal_length: double
  â”œâ”€â”€ sepal_width: double
  â”œâ”€â”€ petal_length: double  
  â”œâ”€â”€ petal_width: double
  â”œâ”€â”€ species: string
  â”œâ”€â”€ processed_timestamp: timestamp
  â””â”€â”€ quality_score: double

-- Gold Layer (Aggregated data)
workspace.default.iris_gold
  â”œâ”€â”€ species: string
  â”œâ”€â”€ avg_sepal_length: double
  â”œâ”€â”€ avg_sepal_width: double
  â”œâ”€â”€ avg_petal_length: double
  â”œâ”€â”€ avg_petal_width: double
  â”œâ”€â”€ sample_count: long
  â””â”€â”€ aggregation_timestamp: timestamp

-- Inference Results (Multiple tables with timestamps)
workspace.default.iris_inference_results_*
  â”œâ”€â”€ sepal_length_cm: double
  â”œâ”€â”€ sepal_width_cm: double
  â”œâ”€â”€ petal_length_cm: double  
  â”œâ”€â”€ petal_width_cm: double
  â”œâ”€â”€ predicted_class: string
  â”œâ”€â”€ confidence: double
  â”œâ”€â”€ inference_timestamp: timestamp
  â”œâ”€â”€ model_name: string
  â””â”€â”€ model_version: string
```

## ğŸ¤– MLflow Integration

### Model Registry
- **Model Name**: `iris_classifier`
- **Stage**: `Production` (ou fallback para modelo de referÃªncia)
- **Algorithm**: RandomForestClassifier
- **Features**: Simplified approach com fallback para quando MLflow nÃ£o estÃ¡ configurado
- **Metrics**: Accuracy, Classification Report, Feature Importance

### Features Implementadas
- âœ… Model training com RandomForestClassifier
- âœ… Fallback quando MLflow registry nÃ£o disponÃ­vel
- âœ… Feature importance tracking
- âœ… Performance monitoring
- âœ… Inference com visualizaÃ§Ãµes completas

## ğŸ“ Estrutura do Projeto

```
â”œâ”€â”€ ğŸ“– CLUSTER_CONFIG_GUIDE.md   # â­ CONFIGURAÃ‡ÃƒO DE CLUSTERS (IMPORTANTE!)
â”œâ”€â”€ resources/jobs/              # Job definitions (5 jobs essenciais)
â”‚   â”œâ”€â”€ bronze_job.yml          # ğŸ¥‰ IngestÃ£o Unity Catalog
â”‚   â”œâ”€â”€ silver_job.yml          # ğŸ¥ˆ TransformaÃ§Ã£o  
â”‚   â”œâ”€â”€ gold_job.yml            # ğŸ¥‡ AgregaÃ§Ã£o
â”‚   â”œâ”€â”€ training_job.yml        # ğŸ¤– ML Training + MLflow
â”‚   â””â”€â”€ inference_job.yml       # ğŸ”® Model Inference + Visualizations
â”œâ”€â”€ notebooks/                   # Implementation notebooks (5 essenciais)
â”‚   â”œâ”€â”€ 01_ingest_bronze.py     # Download Iris + Unity Catalog
â”‚   â”œâ”€â”€ 02_transform_silver.py  # Data cleaning
â”‚   â”œâ”€â”€ 03_aggregate_gold.py    # Analytics aggregations
â”‚   â”œâ”€â”€ 04_train_model.py       # ML training + MLflow
â”‚   â””â”€â”€ 05_model_inference.py   # Model inference + comprehensive visualizations
â”œâ”€â”€ databricks.yml              # Bundle configuration + cluster settings
â”œâ”€â”€ Makefile                    # Automation commands
â””â”€â”€ .github/workflows/          # CI/CD pipeline
    â””â”€â”€ ci-cd-pipeline.yml      # GitHub Actions automation
```

## âš™ï¸ ConfiguraÃ§Ã£o

### VariÃ¡veis de Ambiente (.env)
```bash
DATABRICKS_HOST=https://your-workspace.databricks.com
DATABRICKS_TOKEN=your-token

# Unity Catalog settings (atuais)
catalog_name=workspace
schema_name=default

# Notifications (opcional)
notification_email=your-email@company.com
teams_webhook=https://your-teams-webhook
```

### Deploy
```bash
# 1. Configure environment
cp .env.example .env
# Edit .env with your credentials

# 2. Deploy to Databricks
make validate && make deploy

# 3. Execute pipeline
make run_pipeline
```

### âš¡ ConfiguraÃ§Ã£o AvanÃ§ada de Clusters
Para configurar clusters especÃ­ficos ao invÃ©s de Serverless, consulte:
ğŸ‘‰ **[`CLUSTER_CONFIG_GUIDE.md`](CLUSTER_CONFIG_GUIDE.md)** - Guia completo com exemplos

## ğŸ” Monitoramento

### Verificar Status
```bash
make status         # Status geral do projeto
make list-jobs      # Lista todos os jobs disponÃ­veis  
make help          # Ver todos os comandos
```

### Recursos Implementados
- âœ… **Inference Job** com visualizaÃ§Ãµes completas
- âœ… **Model fallback** quando MLflow nÃ£o disponÃ­vel
- âœ… **Unity Catalog** para todas as tabelas
- âœ… **Serverless Computing** (configurÃ¡vel para clusters especÃ­ficos)
- âœ… **CI/CD Pipeline** com GitHub Actions

## ğŸ¯ BenefÃ­cios

### âœ… Unity Catalog
- **GovernanÃ§a centralizada** de todos os dados
- **Tabelas gerenciadas** com versionamento automÃ¡tico
- **Catalog `workspace`** com schema `default`
- **Lineage tracking** completo

### âœ… Serverless Computing
- **Sem gerenciamento** de clusters
- **Start rÃ¡pido** dos jobs
- **Escalabilidade automÃ¡tica**
- **Pay-per-use** eficiente

### âœ… MLflow Integration
- **Model registry** com fallback robusto
- **Inference completa** com visualizaÃ§Ãµes
- **Performance tracking** detalhado
- **Feature importance** analysis

### âœ… ConfiguraÃ§Ã£o FlexÃ­vel
- **Serverless por padrÃ£o** (sem overhead)
- **Clusters especÃ­ficos** configurÃ¡veis via [`CLUSTER_CONFIG_GUIDE.md`](CLUSTER_CONFIG_GUIDE.md)
- **CI/CD automatizado** com GitHub Actions
- **5 jobs essenciais** bem estruturados

### âœ… ProduÃ§Ã£o Ready
- **Databricks Asset Bundles** para deploy
- **Unity Catalog** para governanÃ§a
- **Comprehensive logging** e monitoramento
- **Pipeline limpo** e documentado

---

## ğŸš€ Quick Start

```bash
# 1. Deploy
make deploy

# 2. Execute pipeline completa
make run_pipeline

# 3. Monitorar
make status
```

## ğŸ“– DocumentaÃ§Ã£o Importante

- ğŸ”§ **[`CLUSTER_CONFIG_GUIDE.md`](CLUSTER_CONFIG_GUIDE.md)** - ConfiguraÃ§Ã£o de clusters (essencial!)
- ğŸ“‹ **[`databricks.yml`](databricks.yml)** - ConfiguraÃ§Ã£o do bundle
- âš™ï¸ **[`Makefile`](Makefile)** - Comandos de automaÃ§Ã£o

**Pipeline MLOps simplificada e pronta para produÃ§Ã£o!** ğŸŒŸ
