# =====================================
# üåê Vari√°veis de ambiente
# =====================================
-include .env
export

# =====================================
# üß™ Comandos principais
# =====================================

# Caminho padr√£o onde a CLI ser√° instalada
DATABRICKS_CLI_DIR := $(HOME)/.databricks/bin
DATABRICKS_BIN := databricks
OS := $(shell uname -s | tr A-Z a-z)

# üõ†Ô∏è Instala Databricks CLI v0.205+ com curl
install-databricks:
	@echo "üöÄ Instalando Databricks CLI oficial (v0.205+)..."
# 	@which databricks >/dev/null 2>&1 && databricks version && echo "‚úÖ J√° instalada!" && exit 0
	@curl -fsSL https://raw.githubusercontent.com/databricks/setup-cli/main/install.sh | sh
	@echo "‚úÖ Databricks CLI instalada com sucesso!"
	@echo "üîç Verificando vers√£o..."
	@which databricks && databricks version



# ‚úÖ Alvo de login com verifica√ß√£o de autentica√ß√£o usando vari√°veis do .env
login:
	@echo "üîê Carregando credenciais do .env..."
	@if [ -f .env ]; then \
		set -a && . ./.env && set +a && \
		databricks workspace list /; \
	else \
		echo "‚ùå Arquivo .env n√£o encontrado!"; \
		exit 1; \
	fi

# üîê Teste simples de autentica√ß√£o sem valida√ß√£o do bundle
test-auth:
	@echo "üîê Testando autentica√ß√£o..."
	@set -a && . ./.env && set +a && \
	cd /tmp && databricks current-user me

# Alvo para validar, fazer deploy e rodar pipeline
validate:
	@set -a && . ./.env && set +a && \
	$(DATABRICKS_BIN) bundle validate

deploy:
	@set -a && . ./.env && set +a && \
	$(DATABRICKS_BIN) bundle deploy --target dev

run:
	@set -a && . ./.env && set +a && \
	$(DATABRICKS_BIN) bundle run iris_pipeline --target dev

test-pipeline:
	@set -a && . ./.env && set +a && \
	$(DATABRICKS_BIN) bundle run test_pipeline --target dev

run_bronze:
	@set -a && . ./.env && set +a && \
	$(DATABRICKS_BIN) bundle run bronze_job --target dev

run_silver:
	@set -a && . ./.env && set +a && \
	$(DATABRICKS_BIN) bundle run silver_job --target dev

run_gold:
	@set -a && . ./.env && set +a && \
	$(DATABRICKS_BIN) bundle run gold_job --target dev 

training_job:
	@set -a && . ./.env && set +a && \
	$(DATABRICKS_BIN) bundle run training_job --target dev

# üß™ Valida√ß√£o de qualidade de dados com Great Expectations
run_data_quality:
	@echo "üß™ Executando valida√ß√£o de qualidade de dados..."
	@set -a && . ./.env && set +a && \
	$(DATABRICKS_BIN) bundle run data_quality_job --target dev

# üè™ Feature Store - Cria√ß√£o e atualiza√ß√£o
run_feature_store:
	@echo "üè™ Criando/atualizando Feature Store..."
	@set -a && . ./.env && set +a && \
	$(DATABRICKS_BIN) bundle run feature_store_job --target dev

# ü§ñ AutoML - Sele√ß√£o autom√°tica de modelos
run_automl:
	@echo "ü§ñ Executando AutoML para sele√ß√£o de modelos..."
	@set -a && . ./.env && set +a && \
	$(DATABRICKS_BIN) bundle run automl_job --target dev

# üìä Model Monitoring - Drift detection
run_monitoring:
	@echo "üìä Executando monitoramento de modelo..."
	@set -a && . ./.env && set +a && \
	$(DATABRICKS_BIN) bundle run model_monitoring_job --target dev

# üöÄ MLOps Pipeline Completo
run_mlops_full:
	@echo "üöÄ Executando pipeline MLOps completo..."
	@set -a && . ./.env && set +a && \
	$(DATABRICKS_BIN) bundle run mlops_full_pipeline --target dev

# üîÑ Workflow completo com depend√™ncias (Bronze ‚Üí Silver ‚Üí Gold ‚Üí Training)
run_workflow:
	@echo "üöÄ Executando workflow completo: Bronze ‚Üí Silver ‚Üí Gold ‚Üí Training..."
	@set -a && . ./.env && set +a && \
	$(DATABRICKS_BIN) bundle run iris_workflow --target dev

# üîó Execu√ß√£o sequencial dos jobs individuais
run_pipeline_sequence:
	@echo "üîó Executando pipeline em sequ√™ncia..."
	@echo "1Ô∏è‚É£ Executando Bronze Job..."
	@$(MAKE) run_bronze
	@echo "2Ô∏è‚É£ Executando Silver Job..."
	@$(MAKE) run_silver
	@echo "3Ô∏è‚É£ Executando Gold Job..."
	@$(MAKE) run_gold
	@echo "4Ô∏è‚É£ Executando Training Job..."
	@$(MAKE) training_job
	@echo "‚úÖ Pipeline completo executado com sucesso!"


list_tables:
	@set -a && . ./.env && set +a && \
	databricks workspace list /Workspace/Users/xultezz@gmail.com/.bundle/iris_bundle/dev/files/notebooks

list_jobs:
	@echo "üìã Listando todos os jobs do bundle..."
	@set -a && . ./.env && set +a && \
	databricks jobs list


schedule_enable:
	@echo "‚úÖ Habilitando agendamento do workflow..."
	@set -a && . ./.env && set +a && \
	JOB_ID=$$(databricks jobs list --output json | jq -r '.jobs[] | select(.settings.name=="iris_complete_workflow") | .job_id'); \
	if [ "$$JOB_ID" != "" ] && [ "$$JOB_ID" != "null" ]; then \
		databricks jobs reset --job-id $$JOB_ID --json-file resources/jobs/iris_workflow.yml; \
		echo "‚úÖ Agendamento habilitado para job ID: $$JOB_ID"; \
	else \
		echo "‚ùå Job 'iris_complete_workflow' n√£o encontrado"; \
	fi

schedule_disable:
	@echo "‚è∏Ô∏è Desabilitando agendamento do workflow..."
	@set -a && . ./.env && set +a && \
	JOB_ID=$$(databricks jobs list --output json | jq -r '.jobs[] | select(.settings.name=="iris_complete_workflow") | .job_id'); \
	if [ "$$JOB_ID" != "" ] && [ "$$JOB_ID" != "null" ]; then \
		databricks jobs update --job-id $$JOB_ID --json '{"schedule": {"pause_status": "PAUSED"}}'; \
		echo "‚è∏Ô∏è Agendamento desabilitado para job ID: $$JOB_ID"; \
	else \
		echo "‚ùå Job 'iris_complete_workflow' n√£o encontrado"; \
	fi

check_schedule:
	@echo "üîç Verificando status do agendamento do job 'iris_complete_workflow'..."
	@set -a && . ./.env && set +a && \
	databricks jobs get 709121597410934

list_runs:
	@echo "üìä Listando execu√ß√µes recentes do workflow..."
	@set -a && . ./.env && set +a && \
	databricks jobs list-runs --job-id 709121597410934 --limit 10

# =====================================
# üßπ Limpeza e debug
# =====================================

clean:
	rm -rf __pycache__ dist *.egg-info .pytest_cache .mypy_cache .coverage

# =====================================
# üí° Ajuda
# =====================================

help:
	@echo "Comandos dispon√≠veis:"
	@echo "  make login               -> Autentica via token"
	@echo "  make validate            -> Valida a estrutura do bundle"
	@echo "  make deploy              -> Sobe c√≥digo e recursos para o Databricks"
	@echo "  make run-pipeline        -> Executa pipeline principal"
	@echo "  make run-test-pipeline   -> Executa pipeline de teste com dados mock"
	@echo "  make logout              -> Remove autentica√ß√£o local"
	@echo "  make clean               -> Remove arquivos tempor√°rios"

# =====================================
# ‚öôÔ∏è Instala√ß√£o do Databricks CLI v2
# =====================================
