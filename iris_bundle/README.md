# ğŸŒ¸ Iris MLOps Pipeline - Databricks Asset Bundles

## ğŸ“‹ VisÃ£o Geral

Pipeline MLOps completo utilizando Databricks Asset Bundles para processamento de dados Iris, desde a ingestÃ£o atÃ© o treinamento de modelos de Machine Learning, seguindo a arquitetura medalion (Bronze â†’ Silver â†’ Gold).

![Pipeline Architecture](https://img.shields.io/badge/Architecture-Medallion-gold)
![Databricks](https://img.shields.io/badge/Databricks-Asset_Bundles-blue)
![Unity Catalog](https://img.shields.io/badge/Unity_Catalog-Enabled-green)
![MLflow](https://img.shields.io/badge/MLflow-Model_Tracking-orange)

## ğŸ—ï¸ Arquitetura do Pipeline

```mermaid
graph TD
    A[ğŸ”µ Bronze Layer<br/>Raw Data Ingestion] --> B[ğŸ¥ˆ Silver Layer<br/>Data Cleaning & Validation]
    B --> C[ğŸ¥‡ Gold Layer<br/>Business Aggregations]
    C --> D[ğŸ¤– ML Training<br/>Model Development]
    
    E[ğŸ“Š Unity Catalog] --> A
    E --> B
    E --> C
    
    D --> F[ğŸ“ˆ MLflow<br/>Model Registry]
    
    style A fill:#8ecae6
    style B fill:#219ebc
    style C fill:#ffb703
    style D fill:#fb8500
```

## ğŸ“ Estrutura do Projeto

```
iris_bundle/
â”œâ”€â”€ ğŸ“„ databricks.yml              # ConfiguraÃ§Ã£o principal do Bundle
â”œâ”€â”€ ğŸ”§ Makefile                    # Comandos de automaÃ§Ã£o
â”œâ”€â”€ ğŸ“‹ requirements.txt            # DependÃªncias Python
â”œâ”€â”€ ğŸ”‘ .env                        # VariÃ¡veis de ambiente (nÃ£o versionado)
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ 01_ingest_bronze.py        # ğŸ”µ IngestÃ£o de dados brutos
â”‚   â”œâ”€â”€ 02_transform_silver.py     # ğŸ¥ˆ Limpeza e validaÃ§Ã£o
â”‚   â”œâ”€â”€ 03_aggregate_gold.py       # ğŸ¥‡ AgregaÃ§Ãµes de negÃ³cio
â”‚   â””â”€â”€ 04_train_model.py          # ğŸ¤– Treinamento ML
â”œâ”€â”€ resources/
â”‚   â””â”€â”€ jobs/
â”‚       â”œâ”€â”€ bronze_job.yml         # Job de ingestÃ£o
â”‚       â”œâ”€â”€ silver_job.yml         # Job de transformaÃ§Ã£o
â”‚       â”œâ”€â”€ gold_job.yml           # Job de agregaÃ§Ã£o
â”‚       â”œâ”€â”€ training_job.yml       # Job de treinamento
â”‚       â””â”€â”€ iris_workflow.yml      # Workflow completo com dependÃªncias
â””â”€â”€ tests/
    â”œâ”€â”€ test_data_quality.py       # Testes de qualidade
    â””â”€â”€ test_iris_reader.py         # Testes unitÃ¡rios
```

## ğŸš€ Quick Start

### 1ï¸âƒ£ PrÃ©-requisitos

- **Databricks CLI v0.261+**
- **Python 3.8+**
- **Workspace Unity Catalog habilitado**
- **Compute Serverless disponÃ­vel**

### 2ï¸âƒ£ InstalaÃ§Ã£o e ConfiguraÃ§Ã£o

```bash
# Clone o repositÃ³rio
git clone <repository-url>
cd iris_bundle

# Instale o Databricks CLI
make install-databricks

# Configure suas credenciais no arquivo .env
cp .env.example .env
# Edite o .env com seus dados:
# DATABRICKS_HOST=https://your-workspace.cloud.databricks.com
# DATABRICKS_TOKEN=dapi12345...
```

### 3ï¸âƒ£ Deploy do Pipeline

```bash
# Valide a configuraÃ§Ã£o
make validate

# FaÃ§a o deploy dos recursos
make deploy

# Execute o workflow completo
make run_workflow
```

## ğŸ“Š Camadas de Dados (Medallion Architecture)

### ğŸ”µ Bronze Layer - Raw Data Ingestion
- **Fonte**: Dataset Iris do seaborn
- **Formato**: Dados brutos sem transformaÃ§Ã£o
- **Tabela**: `default.iris_bronze`
- **CaracterÃ­sticas**:
  - 150 registros
  - 5 colunas (4 features + 1 target)
  - Dados originais preservados

### ğŸ¥ˆ Silver Layer - Data Cleaning & Validation
- **Entrada**: `default.iris_bronze`
- **SaÃ­da**: `default.iris_silver`
- **TransformaÃ§Ãµes**:
  - âœ… RemoÃ§Ã£o de valores nulos
  - âœ… ValidaÃ§Ã£o de schema
  - âœ… Filtros de qualidade (valores > 0)
  - âœ… PadronizaÃ§Ã£o de tipos

### ğŸ¥‡ Gold Layer - Business Aggregations
- **Entrada**: `default.iris_silver`
- **SaÃ­da**: `default.iris_gold`
- **AgregaÃ§Ãµes**:
  - ğŸ“ˆ EstatÃ­sticas por espÃ©cie
  - ğŸ“Š MÃ©dias, medianas, desvios
  - ğŸ”¢ Contagem de registros
  - ğŸ“ Features engineered

### ğŸ¤– ML Training - Model Development
- **Entrada**: `default.iris_gold`
- **SaÃ­da**: Modelo registrado no MLflow
- **CaracterÃ­sticas**:
  - ğŸ¯ Algoritmo: Random Forest Classifier
  - ğŸ“Š MÃ©tricas: Accuracy, Precision, Recall
  - ğŸ·ï¸ Versionamento automÃ¡tico
  - ğŸ“ˆ Tracking completo no MLflow

## âš™ï¸ Comandos DisponÃ­veis

### ğŸ”„ Workflow Completo (Recomendado)
```bash
# Executa pipeline completo com dependÃªncias
make run_workflow
```

### ğŸ”— Jobs Individuais
```bash
# Bronze Layer
make run_bronze

# Silver Layer  
make run_silver

# Gold Layer
make run_gold

# ML Training
make training_job
```

### ğŸ”§ UtilitÃ¡rios
```bash
# ExecuÃ§Ã£o sequencial (sem dependÃªncias)
make run_pipeline_sequence

# ValidaÃ§Ã£o de configuraÃ§Ã£o
make validate

# Re-deploy de alteraÃ§Ãµes
make deploy

# Limpeza de arquivos temporÃ¡rios
make clean
```

## ğŸ› ï¸ ConfiguraÃ§Ã£o Detalhada

### databricks.yml - ConfiguraÃ§Ã£o Principal
```yaml
bundle:
  name: iris_bundle

variables:
  output_bronze_table:
    default: "default.iris_bronze"
  output_silver_table:
    default: "default.iris_silver"
  output_gold_table:
    default: "default.iris_gold"

targets:
  dev:
    default: true
    workspace:
      host: ${var.databricks_host}
```

### Workflow com DependÃªncias
```yaml
# iris_workflow.yml
name: iris_complete_workflow
tasks:
  - task_key: bronze_ingestion      # Primeiro
  - task_key: silver_transform      # Depende do Bronze
    depends_on: [bronze_ingestion]
  - task_key: gold_aggregate        # Depende do Silver
    depends_on: [silver_transform]
  - task_key: model_training        # Depende do Gold
    depends_on: [gold_aggregate]
```

## ğŸ“ˆ Monitoramento e Observabilidade

### MLflow Integration
- **Model Registry**: Versionamento automÃ¡tico de modelos
- **Experiment Tracking**: MÃ©tricas e parÃ¢metros registrados
- **Artifact Storage**: Modelos e artifacts armazenados
- **Model Serving**: Preparado para deployment

### Unity Catalog
- **Governance**: Controle de acesso a dados
- **Lineage**: Rastreabilidade completa de dados
- **Schema Evolution**: Versionamento de schemas
- **Data Discovery**: CatÃ¡logo centralizado

### Job Monitoring
- **Status Tracking**: Monitoramento em tempo real
- **Error Handling**: Logs detalhados de falhas
- **Dependency Management**: ExecuÃ§Ã£o ordenada de tasks
- **Retry Logic**: ReexecuÃ§Ã£o automÃ¡tica em falhas

## ğŸ§ª Testes e Qualidade

### Testes Automatizados
```bash
# ExecuÃ§Ã£o de testes unitÃ¡rios
python -m pytest tests/

# Testes de qualidade de dados
python tests/test_data_quality.py

# Testes de integraÃ§Ã£o
python tests/test_iris_reader.py
```

### ValidaÃ§Ãµes de Dados
- âœ… Schema validation
- âœ… Data quality checks
- âœ… Business rule validation
- âœ… Completeness checks

## ğŸš¨ Troubleshooting

### Problemas Comuns

#### 1. Erro de AutenticaÃ§Ã£o
```bash
# Verifique suas credenciais
make test-auth

# Re-configure o .env se necessÃ¡rio
```

#### 2. Tabelas nÃ£o encontradas
```bash
# Verifique se o Unity Catalog estÃ¡ habilitado
# Execute os jobs em ordem ou use o workflow
make run_workflow
```

#### 3. Compute nÃ£o disponÃ­vel
```bash
# Verifique se o workspace tem Serverless habilitado
# Configure compute_id manualmente se necessÃ¡rio
```

### Logs e Debug
```bash
# Visualize logs detalhados
databricks jobs list-runs --job-id <job-id>

# Acesse o workspace para logs visuais
# URL disponÃ­vel na saÃ­da dos comandos make
```

## ğŸ”„ PrÃ³ximos Passos

### Melhorias Futuras
- [ ] **CI/CD Pipeline**: GitHub Actions integration
- [ ] **Data Validation**: Great Expectations framework
- [ ] **Model Monitoring**: Drift detection
- [ ] **Auto-scaling**: Dynamic cluster management
- [ ] **Multi-environment**: Prod/Staging environments
- [ ] **Real-time Inference**: Streaming predictions
- [ ] **A/B Testing**: Model comparison framework

### ExpansÃµes PossÃ­veis
- [ ] **Feature Store**: Centralized feature management
- [ ] **AutoML**: Automated model selection
- [ ] **Model Serving**: Real-time API endpoints
- [ ] **Batch Inference**: Scheduled predictions
- [ ] **Data Quality Monitoring**: Automated alerts

## ğŸ“š Recursos Adicionais

### DocumentaÃ§Ã£o
- [Databricks Asset Bundles](https://docs.databricks.com/dev-tools/bundles/index.html)
- [Unity Catalog](https://docs.databricks.com/data-governance/unity-catalog/index.html)
- [MLflow on Databricks](https://docs.databricks.com/mlflow/index.html)

### Best Practices
- [Medallion Architecture](https://www.databricks.com/glossary/medallion-architecture)
- [MLOps with Databricks](https://www.databricks.com/solutions/accelerators/mlops)
- [Data Engineering Patterns](https://www.databricks.com/solutions/data-engineering)

## ğŸ¤ ContribuiÃ§Ã£o

1. Fork o projeto
2. Crie uma feature branch (`git checkout -b feature/nova-feature`)
3. Commit suas mudanÃ§as (`git commit -am 'Add nova feature'`)
4. Push para a branch (`git push origin feature/nova-feature`)
5. Abra um Pull Request

## ğŸ“„ LicenÃ§a

Este projeto estÃ¡ sob a licenÃ§a MIT. Veja o arquivo [LICENSE](LICENSE) para mais detalhes.

---

**Desenvolvido com â¤ï¸ para demonstrar MLOps com Databricks Asset Bundles**

*Para dÃºvidas ou suporte, abra uma issue no repositÃ³rio.*
