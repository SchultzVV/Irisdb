# ğŸ“‹ ApresentaÃ§Ã£o: Iris MLOps Pipeline - Databricks Asset Bundles

## ğŸ¯ Slide 1: TÃ­tulo e Objetivos

### ğŸŒ¸ Iris MLOps Pipeline com Databricks Asset Bundles

**DemonstraÃ§Ã£o Completa de Pipeline MLOps**
- âœ… Arquitetura Medallion (Bronze â†’ Silver â†’ Gold)
- âœ… Unity Catalog para GovernanÃ§a de Dados
- âœ… MLflow para Tracking de Modelos
- âœ… Workflow Automatizado com DependÃªncias
- âœ… Infrastructure as Code (IaC)

---

## ğŸ—ï¸ Slide 2: Arquitetura do Sistema

### Componentes Principais:

```
ğŸ“Š Raw Data (Seaborn Iris) 
    â†“
ğŸ”µ Bronze Layer (default.iris_bronze)
    â†“ [Data Validation]
ğŸ¥ˆ Silver Layer (default.iris_silver)
    â†“ [Business Logic]
ğŸ¥‡ Gold Layer (default.iris_gold)
    â†“ [ML Training]
ğŸ¤– MLflow Model Registry
```

**Tecnologias:**
- Databricks Asset Bundles
- Unity Catalog
- Serverless Compute
- MLflow
- Delta Lake

---

## ğŸ“ Slide 3: Estrutura do Projeto

### OrganizaÃ§Ã£o de Arquivos:

```
iris_bundle/
â”œâ”€â”€ ğŸ“„ databricks.yml          # Bundle configuration
â”œâ”€â”€ ğŸ”§ Makefile               # Automation commands
â”œâ”€â”€ notebooks/                # Data processing
â”‚   â”œâ”€â”€ 01_ingest_bronze.py   # Raw data ingestion
â”‚   â”œâ”€â”€ 02_transform_silver.py # Data cleaning
â”‚   â”œâ”€â”€ 03_aggregate_gold.py  # Business aggregations
â”‚   â””â”€â”€ 04_train_model.py     # ML model training
â””â”€â”€ resources/jobs/           # Job definitions
    â”œâ”€â”€ bronze_job.yml
    â”œâ”€â”€ silver_job.yml
    â”œâ”€â”€ gold_job.yml
    â”œâ”€â”€ training_job.yml
    â””â”€â”€ iris_workflow.yml     # Complete workflow
```

---

## ğŸ”µ Slide 4: Bronze Layer - Raw Data Ingestion

### CaracterÃ­sticas:
- **Fonte**: Dataset Iris do seaborn (150 registros)
- **Formato**: Dados brutos preservados
- **LocalizaÃ§Ã£o**: `default.iris_bronze`

### CÃ³digo Principal:
```python
# 01_ingest_bronze.py
import seaborn as sns
df = sns.load_dataset('iris')
spark_df = spark.createDataFrame(df)
spark_df.write.mode("overwrite").saveAsTable(output_table)
```

### Comando de ExecuÃ§Ã£o:
```bash
make run_bronze
```

---

## ğŸ¥ˆ Slide 5: Silver Layer - Data Cleaning & Validation

### TransformaÃ§Ãµes Aplicadas:
- âœ… RemoÃ§Ã£o de valores nulos
- âœ… ValidaÃ§Ã£o de schema
- âœ… Filtros de qualidade (valores > 0)
- âœ… PadronizaÃ§Ã£o de tipos

### CÃ³digo Principal:
```python
# 02_transform_silver.py
df = spark.table(input_bronze_table)
df_clean = (df.dropna()
             .filter(col("sepal_length") > 0)
             .filter(col("sepal_width") > 0))
df_clean.write.mode("overwrite").saveAsTable(output_silver_table)
```

---

## ğŸ¥‡ Slide 6: Gold Layer - Business Aggregations

### MÃ©tricas Calculadas:
- ğŸ“Š EstatÃ­sticas por espÃ©cie (mean, std, count)
- ğŸ“ˆ Features engineered (ratios, areas)
- ğŸ”¢ AgregaÃ§Ãµes de negÃ³cio

### CÃ³digo Principal:
```python
# 03_aggregate_gold.py
stats_by_species = df.groupBy("species").agg(
    avg("sepal_length").alias("avg_sepal_length"),
    avg("sepal_width").alias("avg_sepal_width"),
    count("*").alias("count")
)
```

---

## ğŸ¤– Slide 7: ML Training - Model Development

### CaracterÃ­sticas do Modelo:
- **Algoritmo**: Random Forest Classifier
- **Features**: 4 caracterÃ­sticas fÃ­sicas da Ã­ris
- **Target**: 3 espÃ©cies (setosa, versicolor, virginica)
- **Tracking**: MLflow integration completo

### CÃ³digo Principal:
```python
# 04_train_model.py
rf = RandomForestClassifier(n_estimators=100)
rf.fit(X_train, y_train)
mlflow.sklearn.log_model(rf, "random_forest_model")
mlflow.log_metrics({"accuracy": accuracy, "precision": precision})
```

---

## âš™ï¸ Slide 8: Workflow com DependÃªncias

### iris_workflow.yml:
```yaml
name: iris_complete_workflow
tasks:
  - task_key: bronze_ingestion
    
  - task_key: silver_transform
    depends_on: [bronze_ingestion]
    
  - task_key: gold_aggregate
    depends_on: [silver_transform]
    
  - task_key: model_training
    depends_on: [gold_aggregate]
```

### ExecuÃ§Ã£o:
```bash
make run_workflow  # Pipeline completo automÃ¡tico
```

---

## ğŸ”§ Slide 9: Comandos de AutomaÃ§Ã£o (Makefile)

### Comandos Principais:

```bash
# Setup inicial
make install-databricks
make login
make validate
make deploy

# ExecuÃ§Ã£o
make run_workflow              # Workflow completo (recomendado)
make run_pipeline_sequence     # Sequencial sem dependÃªncias

# Jobs individuais
make run_bronze
make run_silver
make run_gold
make training_job
```

---

## ğŸ“Š Slide 10: Unity Catalog & GovernanÃ§a

### BenefÃ­cios:
- ğŸ” **Controle de Acesso**: PermissÃµes granulares
- ğŸ“ˆ **Data Lineage**: Rastreabilidade completa
- ğŸ·ï¸ **Schema Evolution**: Versionamento de estruturas
- ğŸ” **Data Discovery**: CatÃ¡logo centralizado

### Tabelas Criadas:
- `default.iris_bronze` (dados brutos)
- `default.iris_silver` (dados limpos)
- `default.iris_gold` (agregaÃ§Ãµes)

---

## ğŸ“ˆ Slide 11: MLflow Integration

### Funcionalidades:
- ğŸ·ï¸ **Model Registry**: Versionamento automÃ¡tico
- ğŸ“Š **Experiment Tracking**: MÃ©tricas e parÃ¢metros
- ğŸ“¦ **Artifact Storage**: Modelos e outputs
- ğŸš€ **Model Serving**: Preparado para produÃ§Ã£o

### MÃ©tricas Registradas:
- Accuracy, Precision, Recall, F1-Score
- Feature Importance
- Confusion Matrix
- Training Parameters

---

## ğŸ§ª Slide 12: Testes e Qualidade

### ValidaÃ§Ãµes Implementadas:
- âœ… **Schema Validation**: Estrutura de dados
- âœ… **Data Quality**: Completeness, consistency
- âœ… **Business Rules**: Regras de negÃ³cio
- âœ… **Unit Tests**: Testes automatizados

### Arquivos de Teste:
```
tests/
â”œâ”€â”€ test_data_quality.py     # Qualidade de dados
â”œâ”€â”€ test_iris_reader.py      # Testes unitÃ¡rios
â””â”€â”€ mock_db.py              # Mock para testes
```

---

## ğŸš€ Slide 13: Demo ao Vivo

### Passos da DemonstraÃ§Ã£o:

1. **Verificar Status Inicial**
   ```bash
   make validate
   ```

2. **Deploy do Pipeline**
   ```bash
   make deploy
   ```

3. **Executar Workflow Completo**
   ```bash
   make run_workflow
   ```

4. **Verificar Resultados no Databricks UI**
   - Jobs executados
   - Tabelas criadas no Unity Catalog
   - Modelo registrado no MLflow

---

## ğŸ“Š Slide 14: Resultados Esperados

### MÃ©tricas de Sucesso:
- âœ… **4 Jobs executados** em sequÃªncia com dependÃªncias
- âœ… **3 Tabelas criadas** no Unity Catalog
- âœ… **1 Modelo treinado** e registrado no MLflow
- âœ… **100% de Accuracy** no dataset Iris (esperado)

### EvidÃªncias:
- Logs de execuÃ§Ã£o sem erros
- Tabelas populadas com dados corretos
- Modelo versionado no MLflow Registry
- Lineage completo no Unity Catalog

---

## ğŸ”® Slide 15: PrÃ³ximos Passos e ExtensÃµes

### Melhorias Futuras:

**ğŸ”„ CI/CD Integration**
- GitHub Actions para deployment automÃ¡tico
- Testes automatizados em PRs

**ğŸ“Š Advanced Monitoring**
- Data drift detection
- Model performance monitoring
- Alertas automÃ¡ticos

**ğŸš€ Production Features**
- Multi-environment (dev/staging/prod)
- Real-time inference endpoints
- Feature Store integration

**ğŸ§  Advanced ML**
- AutoML capabilities
- A/B testing framework
- Hyperparameter optimization

---

## ğŸ’¡ Slide 16: Pontos-Chave e Takeaways

### BenefÃ­cios Demonstrados:

**ğŸ—ï¸ Infrastructure as Code**
- ConfiguraÃ§Ã£o versionada e reproduzÃ­vel
- Deploy automatizado e consistente

**ğŸ”„ Pipeline Automation**
- DependÃªncias automÃ¡ticas entre jobs
- ExecuÃ§Ã£o orquestrada e confiÃ¡vel

**ğŸ“Š Data Governance**
- Unity Catalog para controle e lineage
- Qualidade de dados garantida

**ğŸ¤– MLOps Best Practices**
- Model tracking e versionamento
- Reproducibilidade e auditoria

---

## â“ Slide 17: Q&A

### Perguntas Frequentes:

**Q: Como adaptar para outros datasets?**
A: Modificar notebooks e ajustar variÃ¡veis no databricks.yml

**Q: Como escalar para produÃ§Ã£o?**
A: Configurar ambientes mÃºltiplos e compute otimizado

**Q: Como adicionar novos steps?**
A: Criar novo notebook + job YAML + atualizar workflow

**Q: Como monitora falhas?**
A: Logs nativos do Databricks + alertas personalizados

---

## ğŸ“ Slide 18: Contato e Recursos

### Recursos Ãšteis:
- ğŸ“– [Databricks Asset Bundles Docs](https://docs.databricks.com/dev-tools/bundles/)
- ğŸ›ï¸ [Unity Catalog Guide](https://docs.databricks.com/data-governance/unity-catalog/)
- ğŸ§ª [MLflow Documentation](https://mlflow.org/docs/latest/index.html)
- ğŸ—ï¸ [Medallion Architecture](https://www.databricks.com/glossary/medallion-architecture)

### CÃ³digo do Projeto:
- ğŸ“‚ GitHub Repository: `[link-do-repositorio]`
- ğŸ“‹ README completo com instruÃ§Ãµes detalhadas
- ğŸ§ª Testes automatizados inclusos

**Obrigado! ğŸ™**
