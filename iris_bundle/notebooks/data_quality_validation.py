# Databricks notebook source
# MAGIC %md
# MAGIC # üß™ Data Quality Validation with Great Expectations
# MAGIC 
# MAGIC Este notebook implementa valida√ß√µes de qualidade de dados usando Great Expectations em cada camada do pipeline.

# COMMAND ----------

# MAGIC %md
# MAGIC ## üì¶ Setup e Importa√ß√µes

# COMMAND ----------

import great_expectations as gx
from great_expectations.core.batch import RuntimeBatchRequest
from great_expectations.core.yaml_handler import YAMLHandler
import json
import os

# spark e dbutils s√£o dispon√≠veis implicitamente no Databricks
# from pyspark.sql import SparkSession - n√£o necess√°rio no Databricks

# Configura√ß√£o do contexto Great Expectations
context_root_dir = "/Workspace/Users/xultezz@gmail.com/.bundle/iris_bundle/dev/files/great_expectations"

# COMMAND ----------

# MAGIC %md
# MAGIC ## üîß Utility Functions

# COMMAND ----------

def get_ge_context():
    """Obt√©m o contexto do Great Expectations"""
    try:
        context = gx.get_context(context_root_dir=context_root_dir)
        return context
    except Exception as e:
        print(f"‚ùå Erro ao obter contexto GE: {e}")
        return None

def validate_table(table_name, checkpoint_name):
    """
    Valida uma tabela usando um checkpoint espec√≠fico
    
    Args:
        table_name (str): Nome da tabela no Unity Catalog
        checkpoint_name (str): Nome do checkpoint a executar
    
    Returns:
        dict: Resultado da valida√ß√£o
    """
    try:
        context = get_ge_context()
        if not context:
            return {"success": False, "error": "Contexto GE n√£o dispon√≠vel"}
        
        # Criar batch request
        batch_request = RuntimeBatchRequest(
            datasource_name="iris_data",
            data_connector_name="default_runtime_data_connector_name",
            data_asset_name=table_name,
            runtime_parameters={"query": f"SELECT * FROM {table_name}"},
            batch_identifiers={"default_identifier_name": f"{table_name}_batch"}
        )
        
        # Executar checkpoint
        results = context.run_checkpoint(
            checkpoint_name=checkpoint_name,
            validations=[
                {
                    "batch_request": batch_request,
                    "expectation_suite_name": checkpoint_name.replace("_checkpoint", "_suite")
                }
            ]
        )
        
        return {
            "success": results["success"],
            "statistics": results.get("statistics", {}),
            "results": results
        }
        
    except Exception as e:
        return {
            "success": False,
            "error": str(e),
            "table": table_name,
            "checkpoint": checkpoint_name
        }

def print_validation_summary(validation_result, layer_name):
    """Imprime um resumo da valida√ß√£o de forma user-friendly"""
    print(f"\n{'='*60}")
    print(f"üß™ VALIDA√á√ÉO {layer_name.upper()} LAYER")
    print(f"{'='*60}")
    
    if validation_result["success"]:
        print("‚úÖ STATUS: PASSOU EM TODAS AS VALIDA√á√ïES")
        stats = validation_result.get("statistics", {})
        if stats:
            print(f"üìä Expectativas avaliadas: {stats.get('evaluated_expectations', 'N/A')}")
            print(f"‚úÖ Expectativas bem-sucedidas: {stats.get('successful_expectations', 'N/A')}")
            print(f"‚ùå Expectativas falharam: {stats.get('unsuccessful_expectations', 0)}")
            print(f"üìà Taxa de sucesso: {stats.get('success_percent', 'N/A')}%")
    else:
        print("‚ùå STATUS: FALHOU EM ALGUMAS VALIDA√á√ïES")
        print(f"üîç Erro: {validation_result.get('error', 'Erro desconhecido')}")
    
    print(f"{'='*60}\n")

# COMMAND ----------

# MAGIC %md
# MAGIC ## üîµ Bronze Layer Validation

# COMMAND ----------

def validate_bronze_layer():
    """Valida a camada Bronze"""
    print("üîµ Iniciando valida√ß√£o da camada Bronze...")
    
    table_name = "default.iris_bronze"
    checkpoint_name = "iris_bronze_checkpoint"
    
    # Verificar se a tabela existe
    try:
        count = spark.table(table_name).count()
        print(f"üìä Tabela {table_name} encontrada com {count} registros")
    except Exception as e:
        print(f"‚ùå Tabela {table_name} n√£o encontrada: {e}")
        return {"success": False, "error": f"Tabela n√£o existe: {e}"}
    
    # Executar valida√ß√£o
    result = validate_table(table_name, checkpoint_name)
    print_validation_summary(result, "Bronze")
    
    return result

# Executar valida√ß√£o Bronze
bronze_result = validate_bronze_layer()

# COMMAND ----------

# MAGIC %md
# MAGIC ## ü•à Silver Layer Validation

# COMMAND ----------

def validate_silver_layer():
    """Valida a camada Silver"""
    print("ü•à Iniciando valida√ß√£o da camada Silver...")
    
    table_name = "default.iris_silver"
    checkpoint_name = "iris_silver_checkpoint"
    
    # Verificar se a tabela existe
    try:
        count = spark.table(table_name).count()
        print(f"üìä Tabela {table_name} encontrada com {count} registros")
    except Exception as e:
        print(f"‚ùå Tabela {table_name} n√£o encontrada: {e}")
        return {"success": False, "error": f"Tabela n√£o existe: {e}"}
    
    # Executar valida√ß√£o
    result = validate_table(table_name, checkpoint_name)
    print_validation_summary(result, "Silver")
    
    return result

# Executar valida√ß√£o Silver (apenas se Bronze passou)
if bronze_result["success"]:
    silver_result = validate_silver_layer()
else:
    print("‚è≠Ô∏è Pulando valida√ß√£o Silver - Bronze falhou")
    silver_result = {"success": False, "error": "Bronze validation failed"}

# COMMAND ----------

# MAGIC %md
# MAGIC ## ü•á Gold Layer Validation

# COMMAND ----------

def validate_gold_layer():
    """Valida a camada Gold"""
    print("ü•á Iniciando valida√ß√£o da camada Gold...")
    
    table_name = "default.iris_gold"
    checkpoint_name = "iris_gold_checkpoint"
    
    # Verificar se a tabela existe
    try:
        count = spark.table(table_name).count()
        print(f"üìä Tabela {table_name} encontrada com {count} registros")
        
        # Mostrar preview dos dados Gold
        print("üëÄ Preview dos dados Gold:")
        spark.table(table_name).show(5, truncate=False)
        
    except Exception as e:
        print(f"‚ùå Tabela {table_name} n√£o encontrada: {e}")
        return {"success": False, "error": f"Tabela n√£o existe: {e}"}
    
    # Executar valida√ß√£o
    result = validate_table(table_name, checkpoint_name)
    print_validation_summary(result, "Gold")
    
    return result

# Executar valida√ß√£o Gold (apenas se Silver passou)
if silver_result["success"]:
    gold_result = validate_gold_layer()
else:
    print("‚è≠Ô∏è Pulando valida√ß√£o Gold - Silver falhou")
    gold_result = {"success": False, "error": "Silver validation failed"}

# COMMAND ----------

# MAGIC %md
# MAGIC ## üìä Relat√≥rio Final de Qualidade

# COMMAND ----------

def generate_quality_report():
    """Gera relat√≥rio final de qualidade de dados"""
    print("üéØ RELAT√ìRIO FINAL DE QUALIDADE DE DADOS")
    print("="*70)
    
    layers = [
        ("Bronze", bronze_result),
        ("Silver", silver_result), 
        ("Gold", gold_result)
    ]
    
    all_passed = True
    
    for layer_name, result in layers:
        status = "‚úÖ PASSOU" if result["success"] else "‚ùå FALHOU"
        print(f"{layer_name:<10} | {status}")
        
        if not result["success"]:
            all_passed = False
            error = result.get("error", "Erro desconhecido")
            print(f"           | üîç {error}")
    
    print("="*70)
    
    if all_passed:
        print("üéâ PIPELINE DE QUALIDADE: TODOS OS LAYERS PASSARAM!")
        print("‚úÖ Os dados est√£o prontos para uso em produ√ß√£o")
    else:
        print("‚ö†Ô∏è  PIPELINE DE QUALIDADE: ALGUMAS VALIDA√á√ïES FALHARAM")
        print("üîß Revise os dados antes de prosseguir para produ√ß√£o")
    
    print("="*70)
    
    return all_passed

# Gerar relat√≥rio final
pipeline_quality_passed = generate_quality_report()

# COMMAND ----------

# MAGIC %md
# MAGIC ## üö® Alertas e Notifica√ß√µes

# COMMAND ----------

def send_quality_alerts():
    """Envia alertas baseados nos resultados de qualidade"""
    
    if not pipeline_quality_passed:
        print("üö® ALERTA DE QUALIDADE DE DADOS!")
        print("üìß Em produ√ß√£o, isso enviaria:")
        print("   - Email para equipe de dados")
        print("   - Slack notification")
        print("   - Dashboard alert")
        print("   - Log para sistema de monitoramento")
    else:
        print("üîî Notifica√ß√£o: Pipeline de qualidade executado com sucesso")
        print("üìä Dados validados e aprovados para uso")

# Executar alertas
send_quality_alerts()

# COMMAND ----------

# MAGIC %md
# MAGIC ## üìà M√©tricas para Monitoramento

# COMMAND ----------

# Exportar m√©tricas para monitoramento
quality_metrics = {
    "timestamp": dbutils.widgets.get("run_timestamp") if "run_timestamp" in [w.name for w in dbutils.widgets.getAll()] else "manual_run",
    "bronze_validation": bronze_result["success"],
    "silver_validation": silver_result["success"], 
    "gold_validation": gold_result["success"],
    "pipeline_quality_status": pipeline_quality_passed,
    "tables_validated": ["default.iris_bronze", "default.iris_silver", "default.iris_gold"]
}

print("üìä M√©tricas de Qualidade:")
print(json.dumps(quality_metrics, indent=2))

# Em produ√ß√£o, essas m√©tricas seriam enviadas para:
# - CloudWatch/Azure Monitor
# - Datadog
# - Prometheus
# - Sistema interno de m√©tricas
