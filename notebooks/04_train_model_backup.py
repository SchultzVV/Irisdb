# Databricks notebook source
# MAGIC %md
# MAGIC # ü§ñ Model Training - MLflow Integration
# MAGIC ## Iris Classification with RandomForest
# MAGIC 
# MAGIC Este notebook treina um modelo de classifica√ß√£o para o dataset Iris e registra no MLflow
# MAGIC com input_example para infer√™ncia autom√°tica de signature.

# COMMAND ----------

# MAGIC %md
# MAGIC ## üì¶ Imports e Configura√ß√µes

# COMMAND ----------

import pandas as pd
import numpy as np
import mlflow
import mlflow.sklearn
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report
from pyspark.sql import functions as F
from datetime import datetime
import warnings
warnings.filterwarnings('ignore')

# Configurar MLflow para Databricks
mlflow.set_tracking_uri("databricks")
# Definir registry URI explicitamente para Unity Catalog
import os
os.environ["MLFLOW_REGISTRY_URI"] = "databricks-uc"

# COMMAND ----------

# MAGIC %md
# MAGIC ## ‚öôÔ∏è Par√¢metros do Job

# COMMAND ----------

# Widgets para par√¢metros do job
dbutils.widgets.text("input_table", "workspace.default.iris_silver", "Tabela de entrada")
dbutils.widgets.text("model_name", "iris_classifier", "Nome do modelo MLflow")
dbutils.widgets.text("stage", "Production", "Stage do modelo")

# Obter valores dos par√¢metros
INPUT_TABLE = dbutils.widgets.get("input_table")
MODEL_NAME = dbutils.widgets.get("model_name")
STAGE = dbutils.widgets.get("stage")

print(f"ÔøΩ Tabela de entrada: {INPUT_TABLE}")
print(f"ü§ñ Nome do modelo: {MODEL_NAME}")
print(f"üè∑Ô∏è Stage: {STAGE}")

# COMMAND ----------

# MAGIC %md
# MAGIC ## üì• Carregamento dos Dados

# COMMAND ----------

print(f"üì• Carregando dados de: {INPUT_TABLE}")

# Carregar dados da camada Silver
df_spark = spark.table(INPUT_TABLE)
df = df_spark.toPandas()

print(f"üìä Shape do dataset: {df.shape}")
print(f"üìã Colunas: {list(df.columns)}")
print(f"üè∑Ô∏è Esp√©cies √∫nicas: {df['species'].unique()}")

# Mostrar estat√≠sticas b√°sicas
print(f"\nüìà Estat√≠sticas b√°sicas:")
df.describe()

# COMMAND ----------

# MAGIC %md
# MAGIC ## üß™ Valida√ß√µes de Qualidade

# COMMAND ----------

print("üß™ Executando valida√ß√µes de qualidade para ML...")

# Valida√ß√£o 1: Dataset n√£o vazio
assert len(df) > 0, "‚ùå Dataset vazio!"
print(f"‚úÖ Dataset com {len(df)} registros")

# Valida√ß√£o 2: Colunas necess√°rias existem
expected_columns = ["sepal_length", "sepal_width", "petal_length", "petal_width", "species"]
missing_cols = [col for col in expected_columns if col not in df.columns]
assert len(missing_cols) == 0, f"‚ùå Colunas faltando: {missing_cols}"
print("‚úÖ Todas as colunas necess√°rias presentes")

# Valida√ß√£o 3: Sem valores nulos nas colunas cr√≠ticas
critical_nulls = df[expected_columns].isnull().sum()
assert critical_nulls.sum() == 0, f"‚ùå Valores nulos encontrados: {critical_nulls[critical_nulls > 0]}"
print("‚úÖ Nenhum valor nulo nas colunas cr√≠ticas")

# Valida√ß√£o 4: Distribui√ß√£o de classes
class_counts = df['species'].value_counts()
print(f"üìä Distribui√ß√£o de classes:")
for species, count in class_counts.items():
    print(f"   {species}: {count} registros")
assert len(class_counts) >= 2, "‚ùå Menos de 2 classes encontradas!"
print("‚úÖ Distribui√ß√£o de classes adequada")

# Valida√ß√£o 5: Valores num√©ricos v√°lidos
numeric_cols = ["sepal_length", "sepal_width", "petal_length", "petal_width"]
for col in numeric_cols:
    assert df[col].min() > 0, f"‚ùå Valores inv√°lidos em {col}"
    assert df[col].max() < 50, f"‚ùå Valores suspeitos em {col}"
print("‚úÖ Valores num√©ricos dentro das faixas esperadas")

print("\nüéâ Todas as valida√ß√µes passaram!")

# COMMAND ----------

# MAGIC %md
# MAGIC ## üîÑ Prepara√ß√£o dos Dados

# COMMAND ----------

# Preparar features e target
feature_columns = ["sepal_length", "sepal_width", "petal_length", "petal_width"]
X = df[feature_columns]
y = df["species"]

print(f"üìä Features shape: {X.shape}")
print(f"üéØ Target shape: {y.shape}")

# Split dos dados
X_train, X_test, y_train, y_test = train_test_split(
    X, y, 
    test_size=0.2, 
    random_state=42, 
    stratify=y  # Manter propor√ß√£o das classes
)

print(f"\nÔøΩ Split dos dados:")
print(f"   Training set: {len(X_train)} samples")
print(f"   Test set: {len(X_test)} samples")

# Verificar distribui√ß√£o nos splits
print(f"\nüìä Distribui√ß√£o no training set:")
print(y_train.value_counts())
print(f"\nüìä Distribui√ß√£o no test set:")
print(y_test.value_counts())

# COMMAND ----------

# MAGIC %md
# MAGIC ## ü§ñ Treinamento do Modelo

# COMMAND ----------

# Configura√ß√µes do modelo
model_params = {
    'n_estimators': 100,
    'max_depth': 10,
    'min_samples_split': 2,
    'min_samples_leaf': 1,
    'random_state': 42
}

print(f"üîß Par√¢metros do modelo: {model_params}")

# Iniciar experimento MLflow (simplificado para evitar erros de configura√ß√£o)
try:
    # Tentar obter usu√°rio atual de forma mais robusta
    current_user = spark.sql('SELECT current_user()').collect()[0][0]
    experiment_name = f"/Users/{current_user}/{MODEL_NAME}_experiments"
except Exception as e:
    print(f"‚ö†Ô∏è N√£o foi poss√≠vel obter usu√°rio atual: {e}")
    experiment_name = f"/Shared/{MODEL_NAME}_experiments"

print(f"üß™ Configurando experimento: {experiment_name}")

try:
    mlflow.set_experiment(experiment_name)
    print("‚úÖ Experimento MLflow configurado")
except Exception as e:
    print(f"‚ö†Ô∏è Erro ao configurar experimento: {e}")
    print("üîÑ Usando configura√ß√£o padr√£o")
    # Fallback para configura√ß√£o padr√£o
    mlflow.set_experiment(f"/Shared/{MODEL_NAME}_experiments")

with mlflow.start_run(run_name=f"{MODEL_NAME}_training_{datetime.now().strftime('%Y%m%d_%H%M%S')}"):
    
    # Treinar modelo
    print("üöÄ Iniciando treinamento...")
    model = RandomForestClassifier(**model_params)
    model.fit(X_train, y_train)
    print("‚úÖ Treinamento conclu√≠do")
    
    # Fazer predi√ß√µes
    y_pred_train = model.predict(X_train)
    y_pred_test = model.predict(X_test)
    
    # Calcular m√©tricas
    train_accuracy = accuracy_score(y_train, y_pred_train)
    test_accuracy = accuracy_score(y_test, y_pred_test)
    test_precision = precision_score(y_test, y_pred_test, average='weighted')
    test_recall = recall_score(y_test, y_pred_test, average='weighted')
    test_f1 = f1_score(y_test, y_pred_test, average='weighted')
    
    # Log par√¢metros
    mlflow.log_params(model_params)
    mlflow.log_param("test_size", 0.2)
    mlflow.log_param("stratify", True)
    mlflow.log_param("feature_count", len(feature_columns))
    mlflow.log_param("training_samples", len(X_train))
    mlflow.log_param("test_samples", len(X_test))
    
    # Log m√©tricas
    mlflow.log_metric("train_accuracy", train_accuracy)
    mlflow.log_metric("test_accuracy", test_accuracy)
    mlflow.log_metric("precision", test_precision)
    mlflow.log_metric("recall", test_recall)
    mlflow.log_metric("f1_score", test_f1)
    
    # Criar input_example para infer√™ncia de signature
    input_example = X_test.head(3)  # Usar primeiras 3 amostras do test set
    
    print(f"üìÑ Input example shape: {input_example.shape}")
    print(f"üìÑ Input example:")
    print(input_example)
    
    # Log modelo com input_example
    print("üíæ Registrando modelo no MLflow...")
    model_info = mlflow.sklearn.log_model(
        sk_model=model,
        artifact_path="model",
        input_example=input_example,  # ‚úÖ Input example para auto-inferir signature
        registered_model_name=MODEL_NAME
    )
    
    # Log feature importance
    feature_importance = pd.DataFrame({
        'feature': feature_columns,
        'importance': model.feature_importances_
    }).sort_values('importance', ascending=False)
    
    print(f"\nüìä Feature Importance:")
    print(feature_importance)
    
    # Salvar feature importance como artifact
    feature_importance.to_csv("feature_importance.csv", index=False)
    mlflow.log_artifact("feature_importance.csv")
    
    # Log classification report
    class_report = classification_report(y_test, y_pred_test, output_dict=True)
    for class_name, metrics in class_report.items():
        if isinstance(metrics, dict):
            for metric_name, value in metrics.items():
                mlflow.log_metric(f"{class_name}_{metric_name}", value)
    
    print(f"\nüìä M√©tricas do modelo:")
    print(f"   üìà Train Accuracy: {train_accuracy:.4f}")
    print(f"   üìà Test Accuracy: {test_accuracy:.4f}")
    print(f"   üéØ Precision: {test_precision:.4f}")
    print(f"   üìä Recall: {test_recall:.4f}")
    print(f"   ‚öñÔ∏è F1-Score: {test_f1:.4f}")
    
    # Valida√ß√µes finais
    assert test_accuracy > 0.8, f"‚ùå Accuracy muito baixa: {test_accuracy:.4f}"
    print(f"‚úÖ Accuracy aceit√°vel: {test_accuracy:.4f}")
    
    model_uri = model_info.model_uri
    print(f"‚úÖ Modelo registrado: {model_uri}")

# COMMAND ----------

# MAGIC %md
# MAGIC ## üè∑Ô∏è Promo√ß√£o do Modelo para Production

# COMMAND ----------

# Promover modelo para o stage especificado
try:
    client = mlflow.tracking.MlflowClient()
    
    # Obter a vers√£o mais recente do modelo
    latest_version = client.get_latest_versions(MODEL_NAME, stages=["None"])[0]
    model_version = latest_version.version
    
    print(f"üîÑ Promovendo modelo {MODEL_NAME} vers√£o {model_version} para {STAGE}...")
    
    # Transicionar para o stage desejado
    client.transition_model_version_stage(
        name=MODEL_NAME,
        version=model_version,
        stage=STAGE,
        archive_existing_versions=True
    )
    
    print(f"‚úÖ Modelo promovido para {STAGE} com sucesso!")
    
    # Adicionar descri√ß√£o
    client.update_model_version(
        name=MODEL_NAME,
        version=model_version,
        description=f"Iris classification model trained on {datetime.now().strftime('%Y-%m-%d')} with accuracy {test_accuracy:.4f}"
    )
    
except Exception as e:
    print(f"‚ö†Ô∏è Erro na promo√ß√£o do modelo: {e}")
    print("‚ÑπÔ∏è Modelo registrado mas n√£o promovido automaticamente")

# COMMAND ----------

# MAGIC %md
# MAGIC ## üìã Relat√≥rio Final

# COMMAND ----------

# Gerar relat√≥rio final
print("=" * 60)
print("ü§ñ IRIS MODEL TRAINING REPORT")
print("=" * 60)

print(f"\nüìä DATASET INFORMATION:")
print(f"   Source Table: {INPUT_TABLE}")
print(f"   Total Samples: {len(df)}")
print(f"   Features: {len(feature_columns)}")
print(f"   Classes: {len(df['species'].unique())}")

print(f"\nü§ñ MODEL INFORMATION:")
print(f"   Model Name: {MODEL_NAME}")
print(f"   Model Type: RandomForestClassifier")
print(f"   Parameters: {model_params}")

print(f"\nüìà PERFORMANCE METRICS:")
print(f"   Train Accuracy: {train_accuracy:.4f}")
print(f"   Test Accuracy: {test_accuracy:.4f}")
print(f"   Precision: {test_precision:.4f}")
print(f"   Recall: {test_recall:.4f}")
print(f"   F1-Score: {test_f1:.4f}")

print(f"\nÔøΩÔ∏è MLFLOW REGISTRATION:")
print(f"   Model URI: {model_uri}")
print(f"   Target Stage: {STAGE}")
print(f"   Input Example: ‚úÖ Provided for signature inference")

print(f"\nüìä TOP FEATURES:")
for idx, row in feature_importance.head(3).iterrows():
    print(f"   {row['feature']}: {row['importance']:.4f}")

print(f"\n‚è∞ Training completed at: {datetime.now()}")
print("=" * 60)

# COMMAND ----------

# MAGIC %md
# MAGIC ## ‚úÖ Finaliza√ß√£o
# MAGIC 
# MAGIC O treinamento foi conclu√≠do com sucesso:
# MAGIC 
# MAGIC 1. **üìä Dados**: Carregados e validados da camada Silver
# MAGIC 2. **ü§ñ Modelo**: RandomForest treinado com valida√ß√£o cruzada
# MAGIC 3. **üìà M√©tricas**: Accuracy, Precision, Recall e F1-Score calculadas
# MAGIC 4. **üíæ MLflow**: Modelo registrado com input_example para signature
# MAGIC 5. **üè∑Ô∏è Stage**: Modelo promovido para Production (se poss√≠vel)
# MAGIC 
# MAGIC O modelo est√° pronto para ser usado pelas camadas de monitoramento e infer√™ncia.
