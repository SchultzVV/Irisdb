# Databricks notebook source
# MAGIC %md
# MAGIC # ğŸ”® Iris Model Inference & Visualization with MLflow
# MAGIC 
# MAGIC Este notebook:
# MAGIC 1. Carrega modelo do MLflow Registry
# MAGIC 2. Faz inferÃªncias usando Spark UDF
# MAGIC 3. Visualiza os resultados com grÃ¡ficos
# MAGIC 4. Calcula mÃ©tricas de performance

# COMMAND ----------

# Imports necessÃ¡rios
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import mlflow
import mlflow.pyfunc
from pyspark.sql import SparkSession
from pyspark.sql.functions import struct, col, rand, lit
from pyspark.sql.types import StructType, StructField, DoubleType, StringType, TimestampType, IntegerType
from datetime import datetime
import warnings
warnings.filterwarnings('ignore')

# Inicializar Spark session
spark = SparkSession.builder.appName("IrisMLflowInference").getOrCreate()

# Configurar MLflow
mlflow.set_tracking_uri("databricks")

# Configurar estilo dos grÃ¡ficos
plt.style.use('default')
sns.set_palette("husl")

print("ğŸ”® Iniciando job de inferÃªncia do modelo Iris com MLflow...")
print(f"ğŸ“… Timestamp: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")

# COMMAND ----------

# MAGIC %md
# MAGIC ## ğŸ“‹ ParÃ¢metros do Job

# COMMAND ----------

# ParÃ¢metros para inferÃªncia
MODEL_NAME = "iris_classifier"
NUM_SAMPLES = 100

print(f"ğŸ¯ Modelo: {MODEL_NAME}")
print(f"ğŸ“Š Amostras: {NUM_SAMPLES}")

# COMMAND ----------

# MAGIC %md
# MAGIC ## ğŸ¤– Carregamento do Modelo via MLflow

# COMMAND ----------

print("ğŸ” Carregando modelo especÃ­fico do MLflow...")

try:
    # Usar run ID especÃ­fico que vocÃª encontrou
    specific_run_id = "158080ed85b2472081e739ff7eca2354"
    logged_model = f'runs:/{specific_run_id}/model'
    
    print(f"ğŸ¯ Usando run ID especÃ­fico: {specific_run_id}")
    print(f"ğŸ“¦ Model URI: {logged_model}")
    
    # Carregar modelo como Spark UDF
    print("ğŸš€ Carregando modelo como Spark UDF...")
    loaded_model = mlflow.pyfunc.spark_udf(spark, model_uri=logged_model)
    print("âœ… Modelo carregado como Spark UDF com sucesso!")
    
    use_mlflow_model = True
        
except Exception as e:
    print(f"âŒ Erro ao carregar modelo especÃ­fico: {e}")
    print("ğŸ’¡ Tentando buscar modelo automaticamente...")
    
    # Fallback: buscar automaticamente
    try:
        from mlflow.tracking import MlflowClient
        client = MlflowClient()
        current_user = spark.sql('SELECT current_user()').collect()[0][0]
        
        print(f"ğŸ‘¤ UsuÃ¡rio: {current_user}")
        
        # Buscar runs recentes em todos os experimentos
        experiments = client.search_experiments()
        logged_model = None
        
        for experiment in experiments:
            try:
                runs = client.search_runs(
                    experiment_ids=[experiment.experiment_id], 
                    order_by=["start_time DESC"], 
                    max_results=3
                )
                
                for run in runs:
                    run_id = run.info.run_id
                    try:
                        # Verificar se esta run tem um modelo
                        artifacts = client.list_artifacts(run_id)
                        model_artifacts = [a for a in artifacts if a.path == "model"]
                        if model_artifacts:
                            logged_model = f'runs:/{run_id}/model'
                            print(f"âœ… Modelo encontrado automaticamente: {logged_model}")
                            break
                    except:
                        continue
                
                if logged_model:
                    break
                    
            except:
                continue
        
        if logged_model:
            loaded_model = mlflow.pyfunc.spark_udf(spark, model_uri=logged_model)
            print("âœ… Modelo carregado automaticamente!")
            use_mlflow_model = True
        else:
            raise Exception("Nenhum modelo encontrado")
            
    except Exception as fallback_error:
        print(f"âŒ Erro no fallback: {fallback_error}")
        print("âŒ FALHA: NÃ£o foi possÃ­vel carregar modelo do MLflow")
        print("ğŸ’¡ Certifique-se que o modelo foi treinado e registrado corretamente")
        raise Exception("Modelo MLflow obrigatÃ³rio nÃ£o encontrado. Execute o treinamento primeiro.")

# COMMAND ----------

# MAGIC %md
# MAGIC ## ğŸ“Š GeraÃ§Ã£o de Dados SintÃ©ticos para InferÃªncia

# COMMAND ----------

print(f"ğŸ² Gerando {NUM_SAMPLES} amostras sintÃ©ticas em Spark DataFrame...")

# Schema para dados sintÃ©ticos
schema = StructType([
    StructField("sepal_length_cm", DoubleType(), True),
    StructField("sepal_width_cm", DoubleType(), True),
    StructField("petal_length_cm", DoubleType(), True),
    StructField("petal_width_cm", DoubleType(), True),
    StructField("sample_id", IntegerType(), True)
])

# Gerar dados sintÃ©ticos usando estatÃ­sticas realÃ­sticas do Iris
synthetic_data = []
np.random.seed(42)

# EstatÃ­sticas baseadas no dataset Iris real
sepal_length_stats = (5.84, 0.83)  # mÃ©dia, desvio
sepal_width_stats = (3.06, 0.44)
petal_length_stats = (3.76, 1.77)
petal_width_stats = (1.20, 0.76)

for i in range(NUM_SAMPLES):
    row = (
        float(max(0.1, np.random.normal(sepal_length_stats[0], sepal_length_stats[1]))),
        float(max(0.1, np.random.normal(sepal_width_stats[0], sepal_width_stats[1]))),
        float(max(0.1, np.random.normal(petal_length_stats[0], petal_length_stats[1]))),
        float(max(0.1, np.random.normal(petal_width_stats[0], petal_width_stats[1]))),
        i
    )
    synthetic_data.append(row)

# Criar Spark DataFrame
inference_df = spark.createDataFrame(synthetic_data, schema)

print(f"âœ… DataFrame criado com {inference_df.count()} amostras!")
print("ğŸ“Š Schema do DataFrame:")
inference_df.printSchema()

print("ğŸ“ˆ Primeiras 5 amostras:")
inference_df.show(5)

# COMMAND ----------

# MAGIC %md
# MAGIC ## ğŸ”® ExecuÃ§Ã£o da InferÃªncia com MLflow

# COMMAND ----------

print("ğŸš€ Executando inferÃªncia usando MLflow Spark UDF...")

# Usar modelo MLflow obrigatÃ³rio
print("âœ… Usando modelo do MLflow Registry/Run")

# Executar prediÃ§Ã£o usando struct com todas as features
inference_with_predictions = inference_df.withColumn(
    'predictions', 
    loaded_model(struct(
        col("sepal_length_cm"),
        col("sepal_width_cm"), 
        col("petal_length_cm"),
        col("petal_width_cm")
    ))
)

# Adicionar metadados
inference_with_predictions = inference_with_predictions.withColumn(
    "inference_timestamp", 
    lit(datetime.now())
).withColumn(
    "model_name",
    lit(MODEL_NAME)
).withColumn(
    "model_source",
    lit("mlflow")
).withColumn(
    "model_uri",
    lit(logged_model)
)

print("âœ… InferÃªncia concluÃ­da!")
print("ğŸ“Š Resultados da inferÃªncia:")
inference_with_predictions.show(5)

# Converter para pandas para anÃ¡lises e visualizaÃ§Ãµes
results_pd = inference_with_predictions.toPandas()

print(f"ğŸ“Š Total de prediÃ§Ãµes: {len(results_pd)}")
print(f"ğŸ“ˆ DistribuiÃ§Ã£o das prediÃ§Ãµes:")
print(results_pd['predictions'].value_counts().sort_index())

# COMMAND ----------

# MAGIC %md
# MAGIC ## ğŸ“Š VisualizaÃ§Ãµes dos Resultados

# COMMAND ----------

print("ğŸ“ˆ Gerando visualizaÃ§Ãµes...")

# Mapear prediÃ§Ãµes para nomes das classes
class_names = ['setosa', 'versicolor', 'virginica']
results_pd['predicted_class'] = results_pd['predictions'].apply(lambda x: class_names[int(x)])

# Configurar plots
fig, axes = plt.subplots(2, 3, figsize=(18, 12))
fig.suptitle('ğŸ”® MLflow Model Inference - AnÃ¡lise dos Resultados', fontsize=16, fontweight='bold')

# 1. DistribuiÃ§Ã£o das PrediÃ§Ãµes
ax1 = axes[0, 0]
pred_counts = results_pd['predicted_class'].value_counts()
colors = ['#FF6B6B', '#4ECDC4', '#45B7D1']
bars = ax1.bar(pred_counts.index, pred_counts.values, color=colors[:len(pred_counts)])
ax1.set_title('ğŸ“Š DistribuiÃ§Ã£o das PrediÃ§Ãµes')
ax1.set_ylabel('NÃºmero de Amostras')
for bar, count in zip(bars, pred_counts.values):
    height = bar.get_height()
    ax1.text(bar.get_x() + bar.get_width()/2., height + 0.5,
             f'{count}\n({count/len(results_pd)*100:.1f}%)',
             ha='center', va='bottom')

# 2. Boxplot das Features por Classe Predita
ax2 = axes[0, 1]
feature_data = [results_pd[results_pd['predicted_class'] == cls]['sepal_length_cm'].values 
                for cls in class_names if cls in results_pd['predicted_class'].values]
class_labels = [cls for cls in class_names if cls in results_pd['predicted_class'].values]
bp = ax2.boxplot(feature_data, labels=class_labels, patch_artist=True)
for patch, color in zip(bp['boxes'], colors):
    patch.set_facecolor(color)
ax2.set_title('ğŸ“¦ Sepal Length por Classe')
ax2.set_ylabel('Sepal Length (cm)')

# 3. Scatter plot 2D
ax3 = axes[0, 2]
for i, cls in enumerate(class_names):
    if cls in results_pd['predicted_class'].values:
        mask = results_pd['predicted_class'] == cls
        ax3.scatter(results_pd.loc[mask, 'sepal_length_cm'], 
                   results_pd.loc[mask, 'sepal_width_cm'], 
                   c=colors[i], label=cls, alpha=0.6, s=30)
ax3.set_xlabel('Sepal Length (cm)')
ax3.set_ylabel('Sepal Width (cm)')
ax3.set_title('ğŸŒ Sepal Length vs Width')
ax3.legend()
ax3.grid(True, alpha=0.3)

# 4. DistribuiÃ§Ã£o das Features
ax4 = axes[1, 0]
features = ['sepal_length_cm', 'sepal_width_cm', 'petal_length_cm', 'petal_width_cm']
ax4.hist([results_pd[feat] for feat in features], 
         bins=15, alpha=0.7, label=features, color=colors)
ax4.set_title('ğŸ“Š DistribuiÃ§Ã£o das Features')
ax4.set_xlabel('Valor')
ax4.set_ylabel('FrequÃªncia')
ax4.legend()

# 5. Heatmap de CorrelaÃ§Ã£o
ax5 = axes[1, 1]
corr_matrix = results_pd[features].corr()
im = ax5.imshow(corr_matrix, cmap='coolwarm', aspect='auto', vmin=-1, vmax=1)
ax5.set_xticks(range(len(features)))
ax5.set_yticks(range(len(features)))
ax5.set_xticklabels([f.replace('_', '\n') for f in features], rotation=45, ha='right')
ax5.set_yticklabels([f.replace('_', '\n') for f in features])
ax5.set_title('ğŸ”¥ CorrelaÃ§Ã£o entre Features')

for i in range(len(features)):
    for j in range(len(features)):
        text = ax5.text(j, i, f'{corr_matrix.iloc[i, j]:.2f}',
                       ha="center", va="center", color="black", fontsize=8)

# 6. EstatÃ­sticas por Classe
ax6 = axes[1, 2]
class_stats = results_pd.groupby('predicted_class')[features].mean()
class_stats.plot(kind='bar', ax=ax6, color=colors[:len(class_stats)])
ax6.set_title('ğŸ“ˆ MÃ©dias das Features por Classe')
ax6.set_ylabel('Valor MÃ©dio')
ax6.legend(bbox_to_anchor=(1.05, 1), loc='upper left')
ax6.tick_params(axis='x', rotation=45)

plt.tight_layout()
plt.show()

print("âœ… VisualizaÃ§Ãµes geradas com sucesso!")

# COMMAND ----------

# MAGIC %md
# MAGIC ## ğŸ’¾ Salvamento dos Resultados

# COMMAND ----------

print("ğŸ’¾ Salvando resultados da inferÃªncia no Unity Catalog...")

try:
    # Salvar como Delta Table
    results_table_name = f"workspace.default.iris_mlflow_inference_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
    
    inference_with_predictions.write \
        .mode("overwrite") \
        .option("overwriteSchema", "true") \
        .saveAsTable(results_table_name)
    
    print(f"âœ… Resultados salvos em: {results_table_name}")
    print(f"ğŸ“Š Total de registros salvos: {inference_with_predictions.count()}")
    
    # Mostrar uma amostra dos resultados
    print("\nğŸ“Š Amostra dos resultados de inferÃªncia:")
    inference_with_predictions.select(
        "sepal_length_cm", "sepal_width_cm", "petal_length_cm", "petal_width_cm",
        "predictions", "model_source"
    ).show(5)
    
except Exception as e:
    print(f"âš ï¸ Erro ao salvar na tabela Delta: {e}")

# COMMAND ----------

# MAGIC %md
# MAGIC ## ğŸ“‹ RelatÃ³rio Final

# COMMAND ----------

print("\n" + "="*70)
print("ğŸ”® RELATÃ“RIO DE INFERÃŠNCIA - IRIS CLASSIFIER COM MLFLOW")
print("="*70)
print(f"ğŸ“… Data/Hora: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
print(f"ğŸ¯ Modelo: {MODEL_NAME}")
print(f"ğŸ”— Fonte: MLflow Registry/Run")
print(f"ğŸ“¦ Model URI: {logged_model}")
print(f"ğŸ“Š Total de amostras processadas: {len(results_pd)}")

print("\nğŸ“Š DISTRIBUIÃ‡ÃƒO POR CLASSE:")
for cls in class_names:
    if cls in results_pd['predicted_class'].values:
        count = len(results_pd[results_pd['predicted_class'] == cls])
        percentage = count / len(results_pd) * 100
        print(f"  {cls}: {count} amostras ({percentage:.1f}%)")

print("\nğŸ“ˆ ESTATÃSTICAS DAS FEATURES:")
feature_stats = results_pd[features].describe()
print(feature_stats)

print(f"\nâœ… Modelo MLflow utilizado com sucesso!")
print(f"ğŸ”— Model URI: {logged_model}")

print("\nğŸ‰ Job de inferÃªncia MLflow concluÃ­do com sucesso!")
print(f"ğŸ“… Finalizado em: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
print("="*70)
