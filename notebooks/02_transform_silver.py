# Databricks notebook source

# Load data from Bronze layer (Unity Catalog)
from pyspark.sql import SparkSession

# Get parameters from job (with fallback)
try:
    input_bronze_table = dbutils.widgets.get("input_bronze_table")
    output_silver_table = dbutils.widgets.get("output_silver_table")
except:
    input_bronze_table = "workspace.default.iris_bronze"
    output_silver_table = "workspace.default.iris_silver"

# Load data from Bronze table (not DBFS path)
df = spark.table(input_bronze_table)

# ValidaÃ§Ã£o de schema esperada
expected_columns = ["sepal_length", "sepal_width", "petal_length", "petal_width", "species"]
assert df.columns == expected_columns, "âŒ Schema inesperado na Bronze table"

# Exemplo de transformaÃ§Ã£o
df_clean = df.dropna()

# Data cleaning and validation
from pyspark.sql.functions import col
df_clean = (
    df.dropna()
      .filter(col("sepal_length") > 0)
      .filter(col("sepal_width") > 0)
      .filter(col("petal_length") > 0)
      .filter(col("petal_width") > 0)
)

# Save to Silver layer (Unity Catalog table)
df_clean.write.mode("overwrite").option("overwriteSchema", "true").saveAsTable(output_silver_table)

print("âœ… Silver transformation complete")
print(f"âœ… Data saved to table: {output_silver_table}")
print(f"âœ… Cleaned {df_clean.count()} rows")

# ğŸ§ª VALIDAÃ‡Ã•ES SILVER
print("\nğŸ§ª Executando validaÃ§Ãµes Silver...")

# ValidaÃ§Ã£o 1: Sem valores nulos (apÃ³s limpeza)
from pyspark.sql.functions import col, count as spark_count, when

null_counts = df_clean.select([
    spark_count(when(col(c).isNull(), c)).alias(c) for c in df_clean.columns
]).collect()[0]

for col_name in df_clean.columns:
    null_count = null_counts[col_name]
    assert null_count == 0, f"âŒ Silver ainda tem nulos em {col_name}: {null_count}"

print("âœ… Silver: Sem valores nulos")

# ValidaÃ§Ã£o 2: Todos os valores sÃ£o positivos
numeric_cols = ["sepal_length", "sepal_width", "petal_length", "petal_width"]
for col_name in numeric_cols:
    min_val = df_clean.select(col(col_name)).agg({col_name: "min"}).collect()[0][0]
    assert min_val > 0, f"âŒ Valores nÃ£o positivos em {col_name}: {min_val}"

print("âœ… Silver: Todos os valores numÃ©ricos positivos")

# ValidaÃ§Ã£o 3: Contagem razoÃ¡vel apÃ³s limpeza
final_count = df_clean.count()
assert final_count >= 100, f"âŒ Muitos dados perdidos na limpeza: {final_count}"
print(f"âœ… Silver: {final_count} registros limpos mantidos")

print("ğŸ‰ SILVER: Todas as validaÃ§Ãµes passaram!")
